{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for auto-reloading\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Configure pandas to display all columns and rows\n",
    "import pandas as pd\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally force tensorflow on CPU\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "1. [General Usage](#general-usage)\n",
    "    1. [Basic Usage](#basic-usage)\n",
    "    2. [Advanced Usage](#advanced-usage)\n",
    "2. [Data Generation](#data-gen)\n",
    "    1. [Model Synthesis](#model-synth)\n",
    "        1. [Keras Synthesis](#keras-synth)\n",
    "        2. [PyTorch Synthesis](#torch-synth)\n",
    "    2. [Parallel Synthesis](#parallel-synth)\n",
    "        1. [Randomly Generated Networks](#random-synth)\n",
    "3. [Training Prediction Models](#train-models)\n",
    "    1. [Parsing Datasets](#parse-data)\n",
    "        1. [Reading from JSON](#read-json)\n",
    "    2. [Training MLPs](#train-mlps)\n",
    "        1. [Data Preprocessing](#mlp-data)\n",
    "        2. [Building & Training](#fit-mlps)\n",
    "    3. [Training Transformers](#train-transformers)\n",
    "        1. [Data Preprocessing](#transformer-data)\n",
    "        2. [Building & Training](#fit-transformers)\n",
    "    4. [Finetuning (Optional)](#finetune)\n",
    "        1. [Finetuning an MLP](#finetune-mlp)\n",
    "        2. [Loading and Retraining](#load-tuner)\n",
    "4. [Testing Prediction Models](#test-models)\n",
    "    1. [Benchmark Networks](#benchmark-test)\n",
    "    2. [Plots](#plots)\n",
    "        1. [Box Plots](#box-plots)\n",
    "        2. [Bar Plots](#bar-plots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. General Usage <a class=\"anchor\" id=\"general-usage\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section shows both basic and advanced cases of using `rule4ml` for FPGA resources/latency prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Basic Usage <a class=\"anchor\" id=\"basic-usage\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we go through a simple example, using Keras functional API to build a target model and rule4ml `MultiModelEstimator` class for predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 00:39:29.188273: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-15 00:39:29.203356: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-05-15 00:39:29.203377: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-05-15 00:39:29.203859: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-15 00:39:29.207506: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-05-15 00:39:29.630906: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "# Example of a keras Model we want to predict for\n",
    "input_shape = (16,)\n",
    "inputs = keras.layers.Input(shape=input_shape)\n",
    "x = keras.layers.Dense(32, activation=\"relu\")(inputs)\n",
    "x = keras.layers.Dense(32, activation=\"relu\")(x)\n",
    "x = keras.layers.Dense(32, activation=\"relu\")(x)\n",
    "outputs = keras.layers.Dense(5, activation=\"softmax\")(x)\n",
    "\n",
    "model_to_predict = keras.Model(inputs=inputs, outputs=outputs, name=\"Jet Classifier\")\n",
    "model_to_predict.build((None, *input_shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling `load_default_models` will load the weights included within the package for each resource and latency predictor.\n",
    "\n",
    "Currently the predicted resources are BRAM, DSP, FF and LUT, while latency refers to the number of clock cycles required for an inference of the target model(s).\n",
    "\n",
    "**Important:** Since the predictors are trained and their weights are saved using a specific TF/Keras version, using a lower version might break weight loading. In case weight loading fails, check if your installed version matches [setup.cfg](https://github.com/IMPETUS-UdeS/rule4ml/blob/main/setup.cfg)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rule4ml.models.estimators import MultiModelEstimator\n",
    "\n",
    "# Loading default weights\n",
    "estimator = MultiModelEstimator()\n",
    "estimator.load_default_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After building the target model and loading the predictors weights, what's left is to call `predict`.\n",
    "\n",
    "In case the target models are the only argument passed to the `predict` method, predictions are made for hls4ml configurations seen during training.\n",
    "\n",
    "Later on, we will see how to make a specific configuration we're interested in and pass it as an argument to `predict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "('Model', 'Board', 'Strategy', 'Precision', 'Reuse Factor')",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "BRAM (%)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "DSP (%)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "FF (%)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "LUT (%)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "CYCLES",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "cd59e547-c1c7-4103-b01b-62fb70cf1e96",
       "rows": [
        [
         "('Jet Classifier', 'pynq-z2', 'Latency', 'ap_fixed<2, 1>', 1)",
         "2.77",
         "0.89",
         "2.63",
         "30.02",
         "54.68"
        ],
        [
         "('Jet Classifier', 'pynq-z2', 'Latency', 'ap_fixed<2, 1>', 2)",
         "2.75",
         "0.86",
         "2.62",
         "29.91",
         "55.84"
        ],
        [
         "('Jet Classifier', 'pynq-z2', 'Latency', 'ap_fixed<2, 1>', 4)",
         "2.7",
         "0.79",
         "2.58",
         "29.8",
         "55.78"
        ],
        [
         "('Jet Classifier', 'pynq-z2', 'Latency', 'ap_fixed<2, 1>', 8)",
         "2.97",
         "0.67",
         "2.49",
         "29.79",
         "68.84"
        ],
        [
         "('Jet Classifier', 'pynq-z2', 'Latency', 'ap_fixed<2, 1>', 16)",
         "2.97",
         "0.63",
         "2.5",
         "30.24",
         "75.38"
        ],
        [
         "('Jet Classifier', 'pynq-z2', 'Latency', 'ap_fixed<2, 1>', 32)",
         "2.26",
         "0.74",
         "2.43",
         "30.9",
         "76.19"
        ],
        [
         "('Jet Classifier', 'pynq-z2', 'Latency', 'ap_fixed<2, 1>', 64)",
         "0.83",
         "0.47",
         "2.19",
         "32.89",
         "112.04"
        ],
        [
         "('Jet Classifier', 'pynq-z2', 'Latency', 'ap_fixed<8, 3>', 1)",
         "2.63",
         "1.58",
         "13.91",
         "115.89",
         "53.96"
        ],
        [
         "('Jet Classifier', 'pynq-z2', 'Latency', 'ap_fixed<8, 3>', 2)",
         "2.63",
         "1.5",
         "13.63",
         "111.75",
         "54.7"
        ],
        [
         "('Jet Classifier', 'pynq-z2', 'Latency', 'ap_fixed<8, 3>', 4)",
         "2.59",
         "1.25",
         "13.07",
         "108.52",
         "56.16"
        ],
        [
         "('Jet Classifier', 'pynq-z2', 'Latency', 'ap_fixed<8, 3>', 8)",
         "2.76",
         "1.41",
         "12.22",
         "108.01",
         "53.07"
        ],
        [
         "('Jet Classifier', 'pynq-z2', 'Latency', 'ap_fixed<8, 3>', 16)",
         "3.42",
         "1.96",
         "11.98",
         "104.58",
         "64.71"
        ],
        [
         "('Jet Classifier', 'pynq-z2', 'Latency', 'ap_fixed<8, 3>', 32)",
         "2.99",
         "1.93",
         "12.74",
         "94.71",
         "83.06"
        ],
        [
         "('Jet Classifier', 'pynq-z2', 'Latency', 'ap_fixed<8, 3>', 64)",
         "0.56",
         "1.7",
         "14.74",
         "92.78",
         "104.88"
        ],
        [
         "('Jet Classifier', 'pynq-z2', 'Latency', 'ap_fixed<16, 6>', 1)",
         "1.78",
         "199.86",
         "45.96",
         "184.86",
         "66.59"
        ],
        [
         "('Jet Classifier', 'pynq-z2', 'Latency', 'ap_fixed<16, 6>', 2)",
         "2.3",
         "198.3",
         "45.71",
         "190.51",
         "68.14"
        ],
        [
         "('Jet Classifier', 'pynq-z2', 'Latency', 'ap_fixed<16, 6>', 4)",
         "2.38",
         "198.5",
         "45.95",
         "195.05",
         "73.15"
        ],
        [
         "('Jet Classifier', 'pynq-z2', 'Latency', 'ap_fixed<16, 6>', 8)",
         "1.48",
         "175.18",
         "46.42",
         "188.65",
         "95.7"
        ],
        [
         "('Jet Classifier', 'pynq-z2', 'Latency', 'ap_fixed<16, 6>', 16)",
         "2.9",
         "83.85",
         "48.13",
         "184.96",
         "101.44"
        ],
        [
         "('Jet Classifier', 'pynq-z2', 'Latency', 'ap_fixed<16, 6>', 32)",
         "4.43",
         "51.04",
         "51.83",
         "193.38",
         "141.07"
        ],
        [
         "('Jet Classifier', 'pynq-z2', 'Latency', 'ap_fixed<16, 6>', 64)",
         "0.75",
         "30.32",
         "55.36",
         "193.26",
         "229.37"
        ],
        [
         "('Jet Classifier', 'pynq-z2', 'Resource', 'ap_fixed<2, 1>', 1)",
         "5.67",
         "0.9",
         "4.57",
         "76.14",
         "75.22"
        ],
        [
         "('Jet Classifier', 'pynq-z2', 'Resource', 'ap_fixed<2, 1>', 2)",
         "34.49",
         "0.89",
         "4.56",
         "149.7",
         "78.89"
        ],
        [
         "('Jet Classifier', 'pynq-z2', 'Resource', 'ap_fixed<2, 1>', 4)",
         "13.99",
         "0.82",
         "4.6",
         "174.11",
         "89.72"
        ],
        [
         "('Jet Classifier', 'pynq-z2', 'Resource', 'ap_fixed<2, 1>', 8)",
         "10.2",
         "0.69",
         "4.85",
         "139.49",
         "111.75"
        ],
        [
         "('Jet Classifier', 'pynq-z2', 'Resource', 'ap_fixed<2, 1>', 16)",
         "7.84",
         "0.66",
         "5.28",
         "70.91",
         "132.12"
        ],
        [
         "('Jet Classifier', 'pynq-z2', 'Resource', 'ap_fixed<2, 1>', 32)",
         "4.2",
         "0.77",
         "4.46",
         "39.63",
         "208.69"
        ],
        [
         "('Jet Classifier', 'pynq-z2', 'Resource', 'ap_fixed<2, 1>', 64)",
         "3.44",
         "0.48",
         "3.94",
         "45.27",
         "304.05"
        ],
        [
         "('Jet Classifier', 'pynq-z2', 'Resource', 'ap_fixed<8, 3>', 1)",
         "10.05",
         "1.6",
         "23.77",
         "141.49",
         "68.06"
        ],
        [
         "('Jet Classifier', 'pynq-z2', 'Resource', 'ap_fixed<8, 3>', 2)",
         "55.8",
         "1.52",
         "22.87",
         "183.85",
         "73.07"
        ],
        [
         "('Jet Classifier', 'pynq-z2', 'Resource', 'ap_fixed<8, 3>', 4)",
         "55.67",
         "1.27",
         "20.98",
         "198.83",
         "77.51"
        ],
        [
         "('Jet Classifier', 'pynq-z2', 'Resource', 'ap_fixed<8, 3>', 8)",
         "20.88",
         "1.43",
         "18.04",
         "165.3",
         "97.81"
        ],
        [
         "('Jet Classifier', 'pynq-z2', 'Resource', 'ap_fixed<8, 3>', 16)",
         "11.99",
         "2.0",
         "15.51",
         "115.64",
         "159.26"
        ],
        [
         "('Jet Classifier', 'pynq-z2', 'Resource', 'ap_fixed<8, 3>', 32)",
         "5.06",
         "1.98",
         "11.13",
         "72.22",
         "187.69"
        ],
        [
         "('Jet Classifier', 'pynq-z2', 'Resource', 'ap_fixed<8, 3>', 64)",
         "3.01",
         "1.75",
         "9.3",
         "67.29",
         "333.98"
        ],
        [
         "('Jet Classifier', 'pynq-z2', 'Resource', 'ap_fixed<16, 6>', 1)",
         "11.69",
         "199.97",
         "59.83",
         "187.63",
         "75.57"
        ],
        [
         "('Jet Classifier', 'pynq-z2', 'Resource', 'ap_fixed<16, 6>', 2)",
         "119.1",
         "198.44",
         "57.58",
         "195.18",
         "75.91"
        ],
        [
         "('Jet Classifier', 'pynq-z2', 'Resource', 'ap_fixed<16, 6>', 4)",
         "89.59",
         "198.63",
         "52.5",
         "197.65",
         "83.27"
        ],
        [
         "('Jet Classifier', 'pynq-z2', 'Resource', 'ap_fixed<16, 6>', 8)",
         "47.71",
         "175.83",
         "43.0",
         "196.3",
         "122.93"
        ],
        [
         "('Jet Classifier', 'pynq-z2', 'Resource', 'ap_fixed<16, 6>', 16)",
         "27.98",
         "84.48",
         "29.85",
         "145.65",
         "195.46"
        ],
        [
         "('Jet Classifier', 'pynq-z2', 'Resource', 'ap_fixed<16, 6>', 32)",
         "9.69",
         "51.36",
         "20.54",
         "116.51",
         "239.0"
        ],
        [
         "('Jet Classifier', 'pynq-z2', 'Resource', 'ap_fixed<16, 6>', 64)",
         "5.45",
         "30.57",
         "15.79",
         "117.74",
         "361.06"
        ],
        [
         "('Jet Classifier', 'zcu102', 'Latency', 'ap_fixed<2, 1>', 1)",
         "0.71",
         "0.0",
         "0.16",
         "7.57",
         "36.51"
        ],
        [
         "('Jet Classifier', 'zcu102', 'Latency', 'ap_fixed<2, 1>', 2)",
         "0.71",
         "0.0",
         "0.17",
         "7.47",
         "37.45"
        ],
        [
         "('Jet Classifier', 'zcu102', 'Latency', 'ap_fixed<2, 1>', 4)",
         "0.75",
         "0.0",
         "0.19",
         "7.5",
         "41.43"
        ],
        [
         "('Jet Classifier', 'zcu102', 'Latency', 'ap_fixed<2, 1>', 8)",
         "0.84",
         "0.0",
         "0.21",
         "7.17",
         "54.65"
        ],
        [
         "('Jet Classifier', 'zcu102', 'Latency', 'ap_fixed<2, 1>', 16)",
         "0.81",
         "0.0",
         "0.12",
         "5.87",
         "55.57"
        ],
        [
         "('Jet Classifier', 'zcu102', 'Latency', 'ap_fixed<2, 1>', 32)",
         "0.38",
         "0.0",
         "0.0",
         "4.53",
         "51.7"
        ],
        [
         "('Jet Classifier', 'zcu102', 'Latency', 'ap_fixed<2, 1>', 64)",
         "0.54",
         "0.0",
         "0.01",
         "6.98",
         "106.39"
        ],
        [
         "('Jet Classifier', 'zcu102', 'Latency', 'ap_fixed<8, 3>', 1)",
         "0.57",
         "0.0",
         "0.17",
         "26.85",
         "41.56"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 126
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>BRAM (%)</th>\n",
       "      <th>DSP (%)</th>\n",
       "      <th>FF (%)</th>\n",
       "      <th>LUT (%)</th>\n",
       "      <th>CYCLES</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th>Board</th>\n",
       "      <th>Strategy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Reuse Factor</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"126\" valign=\"top\">Jet Classifier</th>\n",
       "      <th rowspan=\"42\" valign=\"top\">pynq-z2</th>\n",
       "      <th rowspan=\"21\" valign=\"top\">Latency</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">ap_fixed&lt;2, 1&gt;</th>\n",
       "      <th>1</th>\n",
       "      <td>2.77</td>\n",
       "      <td>0.89</td>\n",
       "      <td>2.63</td>\n",
       "      <td>30.02</td>\n",
       "      <td>54.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.75</td>\n",
       "      <td>0.86</td>\n",
       "      <td>2.62</td>\n",
       "      <td>29.91</td>\n",
       "      <td>55.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.70</td>\n",
       "      <td>0.79</td>\n",
       "      <td>2.58</td>\n",
       "      <td>29.80</td>\n",
       "      <td>55.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.97</td>\n",
       "      <td>0.67</td>\n",
       "      <td>2.49</td>\n",
       "      <td>29.79</td>\n",
       "      <td>68.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.97</td>\n",
       "      <td>0.63</td>\n",
       "      <td>2.50</td>\n",
       "      <td>30.24</td>\n",
       "      <td>75.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2.26</td>\n",
       "      <td>0.74</td>\n",
       "      <td>2.43</td>\n",
       "      <td>30.90</td>\n",
       "      <td>76.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.47</td>\n",
       "      <td>2.19</td>\n",
       "      <td>32.89</td>\n",
       "      <td>112.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">ap_fixed&lt;8, 3&gt;</th>\n",
       "      <th>1</th>\n",
       "      <td>2.63</td>\n",
       "      <td>1.58</td>\n",
       "      <td>13.91</td>\n",
       "      <td>115.89</td>\n",
       "      <td>53.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.63</td>\n",
       "      <td>1.50</td>\n",
       "      <td>13.63</td>\n",
       "      <td>111.75</td>\n",
       "      <td>54.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.59</td>\n",
       "      <td>1.25</td>\n",
       "      <td>13.07</td>\n",
       "      <td>108.52</td>\n",
       "      <td>56.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.76</td>\n",
       "      <td>1.41</td>\n",
       "      <td>12.22</td>\n",
       "      <td>108.01</td>\n",
       "      <td>53.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3.42</td>\n",
       "      <td>1.96</td>\n",
       "      <td>11.98</td>\n",
       "      <td>104.58</td>\n",
       "      <td>64.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2.99</td>\n",
       "      <td>1.93</td>\n",
       "      <td>12.74</td>\n",
       "      <td>94.71</td>\n",
       "      <td>83.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.56</td>\n",
       "      <td>1.70</td>\n",
       "      <td>14.74</td>\n",
       "      <td>92.78</td>\n",
       "      <td>104.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">ap_fixed&lt;16, 6&gt;</th>\n",
       "      <th>1</th>\n",
       "      <td>1.78</td>\n",
       "      <td>199.86</td>\n",
       "      <td>45.96</td>\n",
       "      <td>184.86</td>\n",
       "      <td>66.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.30</td>\n",
       "      <td>198.30</td>\n",
       "      <td>45.71</td>\n",
       "      <td>190.51</td>\n",
       "      <td>68.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.38</td>\n",
       "      <td>198.50</td>\n",
       "      <td>45.95</td>\n",
       "      <td>195.05</td>\n",
       "      <td>73.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.48</td>\n",
       "      <td>175.18</td>\n",
       "      <td>46.42</td>\n",
       "      <td>188.65</td>\n",
       "      <td>95.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.90</td>\n",
       "      <td>83.85</td>\n",
       "      <td>48.13</td>\n",
       "      <td>184.96</td>\n",
       "      <td>101.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>4.43</td>\n",
       "      <td>51.04</td>\n",
       "      <td>51.83</td>\n",
       "      <td>193.38</td>\n",
       "      <td>141.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.75</td>\n",
       "      <td>30.32</td>\n",
       "      <td>55.36</td>\n",
       "      <td>193.26</td>\n",
       "      <td>229.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"21\" valign=\"top\">Resource</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">ap_fixed&lt;2, 1&gt;</th>\n",
       "      <th>1</th>\n",
       "      <td>5.67</td>\n",
       "      <td>0.90</td>\n",
       "      <td>4.57</td>\n",
       "      <td>76.14</td>\n",
       "      <td>75.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34.49</td>\n",
       "      <td>0.89</td>\n",
       "      <td>4.56</td>\n",
       "      <td>149.70</td>\n",
       "      <td>78.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.99</td>\n",
       "      <td>0.82</td>\n",
       "      <td>4.60</td>\n",
       "      <td>174.11</td>\n",
       "      <td>89.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10.20</td>\n",
       "      <td>0.69</td>\n",
       "      <td>4.85</td>\n",
       "      <td>139.49</td>\n",
       "      <td>111.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7.84</td>\n",
       "      <td>0.66</td>\n",
       "      <td>5.28</td>\n",
       "      <td>70.91</td>\n",
       "      <td>132.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>4.20</td>\n",
       "      <td>0.77</td>\n",
       "      <td>4.46</td>\n",
       "      <td>39.63</td>\n",
       "      <td>208.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>3.44</td>\n",
       "      <td>0.48</td>\n",
       "      <td>3.94</td>\n",
       "      <td>45.27</td>\n",
       "      <td>304.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">ap_fixed&lt;8, 3&gt;</th>\n",
       "      <th>1</th>\n",
       "      <td>10.05</td>\n",
       "      <td>1.60</td>\n",
       "      <td>23.77</td>\n",
       "      <td>141.49</td>\n",
       "      <td>68.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55.80</td>\n",
       "      <td>1.52</td>\n",
       "      <td>22.87</td>\n",
       "      <td>183.85</td>\n",
       "      <td>73.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55.67</td>\n",
       "      <td>1.27</td>\n",
       "      <td>20.98</td>\n",
       "      <td>198.83</td>\n",
       "      <td>77.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20.88</td>\n",
       "      <td>1.43</td>\n",
       "      <td>18.04</td>\n",
       "      <td>165.30</td>\n",
       "      <td>97.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>11.99</td>\n",
       "      <td>2.00</td>\n",
       "      <td>15.51</td>\n",
       "      <td>115.64</td>\n",
       "      <td>159.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>5.06</td>\n",
       "      <td>1.98</td>\n",
       "      <td>11.13</td>\n",
       "      <td>72.22</td>\n",
       "      <td>187.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>3.01</td>\n",
       "      <td>1.75</td>\n",
       "      <td>9.30</td>\n",
       "      <td>67.29</td>\n",
       "      <td>333.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">ap_fixed&lt;16, 6&gt;</th>\n",
       "      <th>1</th>\n",
       "      <td>11.69</td>\n",
       "      <td>199.97</td>\n",
       "      <td>59.83</td>\n",
       "      <td>187.63</td>\n",
       "      <td>75.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>119.10</td>\n",
       "      <td>198.44</td>\n",
       "      <td>57.58</td>\n",
       "      <td>195.18</td>\n",
       "      <td>75.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89.59</td>\n",
       "      <td>198.63</td>\n",
       "      <td>52.50</td>\n",
       "      <td>197.65</td>\n",
       "      <td>83.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>47.71</td>\n",
       "      <td>175.83</td>\n",
       "      <td>43.00</td>\n",
       "      <td>196.30</td>\n",
       "      <td>122.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>27.98</td>\n",
       "      <td>84.48</td>\n",
       "      <td>29.85</td>\n",
       "      <td>145.65</td>\n",
       "      <td>195.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>9.69</td>\n",
       "      <td>51.36</td>\n",
       "      <td>20.54</td>\n",
       "      <td>116.51</td>\n",
       "      <td>239.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>5.45</td>\n",
       "      <td>30.57</td>\n",
       "      <td>15.79</td>\n",
       "      <td>117.74</td>\n",
       "      <td>361.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"42\" valign=\"top\">zcu102</th>\n",
       "      <th rowspan=\"21\" valign=\"top\">Latency</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">ap_fixed&lt;2, 1&gt;</th>\n",
       "      <th>1</th>\n",
       "      <td>0.71</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>7.57</td>\n",
       "      <td>36.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.71</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>7.47</td>\n",
       "      <td>37.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.19</td>\n",
       "      <td>7.50</td>\n",
       "      <td>41.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.21</td>\n",
       "      <td>7.17</td>\n",
       "      <td>54.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.12</td>\n",
       "      <td>5.87</td>\n",
       "      <td>55.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.53</td>\n",
       "      <td>51.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.54</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>6.98</td>\n",
       "      <td>106.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">ap_fixed&lt;8, 3&gt;</th>\n",
       "      <th>1</th>\n",
       "      <td>0.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>26.85</td>\n",
       "      <td>41.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.54</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>26.28</td>\n",
       "      <td>42.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.48</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.23</td>\n",
       "      <td>26.49</td>\n",
       "      <td>44.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.47</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>26.13</td>\n",
       "      <td>46.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.47</td>\n",
       "      <td>25.94</td>\n",
       "      <td>45.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.68</td>\n",
       "      <td>25.22</td>\n",
       "      <td>56.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.88</td>\n",
       "      <td>23.51</td>\n",
       "      <td>74.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">ap_fixed&lt;16, 6&gt;</th>\n",
       "      <th>1</th>\n",
       "      <td>0.65</td>\n",
       "      <td>109.08</td>\n",
       "      <td>1.75</td>\n",
       "      <td>47.02</td>\n",
       "      <td>48.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.62</td>\n",
       "      <td>75.48</td>\n",
       "      <td>1.94</td>\n",
       "      <td>48.70</td>\n",
       "      <td>54.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.58</td>\n",
       "      <td>35.35</td>\n",
       "      <td>2.35</td>\n",
       "      <td>50.72</td>\n",
       "      <td>59.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.50</td>\n",
       "      <td>17.65</td>\n",
       "      <td>3.13</td>\n",
       "      <td>48.29</td>\n",
       "      <td>76.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.63</td>\n",
       "      <td>7.18</td>\n",
       "      <td>4.57</td>\n",
       "      <td>48.69</td>\n",
       "      <td>109.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.65</td>\n",
       "      <td>4.68</td>\n",
       "      <td>5.85</td>\n",
       "      <td>49.10</td>\n",
       "      <td>115.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.48</td>\n",
       "      <td>3.02</td>\n",
       "      <td>6.33</td>\n",
       "      <td>40.80</td>\n",
       "      <td>200.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"21\" valign=\"top\">Resource</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">ap_fixed&lt;2, 1&gt;</th>\n",
       "      <th>1</th>\n",
       "      <td>1.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.53</td>\n",
       "      <td>8.82</td>\n",
       "      <td>61.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.81</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.52</td>\n",
       "      <td>30.46</td>\n",
       "      <td>64.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.68</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.49</td>\n",
       "      <td>31.68</td>\n",
       "      <td>74.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.40</td>\n",
       "      <td>29.44</td>\n",
       "      <td>92.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.33</td>\n",
       "      <td>18.45</td>\n",
       "      <td>91.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.33</td>\n",
       "      <td>12.30</td>\n",
       "      <td>182.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.21</td>\n",
       "      <td>288.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">ap_fixed&lt;8, 3&gt;</th>\n",
       "      <th>1</th>\n",
       "      <td>2.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.93</td>\n",
       "      <td>26.10</td>\n",
       "      <td>55.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>54.43</td>\n",
       "      <td>59.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.02</td>\n",
       "      <td>72.25</td>\n",
       "      <td>62.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.14</td>\n",
       "      <td>48.05</td>\n",
       "      <td>78.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.22</td>\n",
       "      <td>28.90</td>\n",
       "      <td>141.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.27</td>\n",
       "      <td>14.83</td>\n",
       "      <td>179.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.28</td>\n",
       "      <td>14.77</td>\n",
       "      <td>296.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">ap_fixed&lt;16, 6&gt;</th>\n",
       "      <th>1</th>\n",
       "      <td>2.25</td>\n",
       "      <td>109.62</td>\n",
       "      <td>1.69</td>\n",
       "      <td>52.05</td>\n",
       "      <td>61.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32.38</td>\n",
       "      <td>75.81</td>\n",
       "      <td>1.78</td>\n",
       "      <td>73.82</td>\n",
       "      <td>63.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21.17</td>\n",
       "      <td>35.48</td>\n",
       "      <td>1.95</td>\n",
       "      <td>89.13</td>\n",
       "      <td>68.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11.52</td>\n",
       "      <td>17.76</td>\n",
       "      <td>2.12</td>\n",
       "      <td>58.20</td>\n",
       "      <td>98.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5.19</td>\n",
       "      <td>7.22</td>\n",
       "      <td>2.27</td>\n",
       "      <td>31.63</td>\n",
       "      <td>153.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.55</td>\n",
       "      <td>4.71</td>\n",
       "      <td>2.40</td>\n",
       "      <td>20.12</td>\n",
       "      <td>215.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.91</td>\n",
       "      <td>3.03</td>\n",
       "      <td>2.23</td>\n",
       "      <td>21.29</td>\n",
       "      <td>347.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"42\" valign=\"top\">alveo-u200</th>\n",
       "      <th rowspan=\"21\" valign=\"top\">Latency</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">ap_fixed&lt;2, 1&gt;</th>\n",
       "      <th>1</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>37.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.53</td>\n",
       "      <td>35.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>37.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.68</td>\n",
       "      <td>53.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.07</td>\n",
       "      <td>54.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.41</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>51.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>109.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">ap_fixed&lt;8, 3&gt;</th>\n",
       "      <th>1</th>\n",
       "      <td>0.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>4.02</td>\n",
       "      <td>41.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>4.05</td>\n",
       "      <td>43.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>4.30</td>\n",
       "      <td>44.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.19</td>\n",
       "      <td>4.34</td>\n",
       "      <td>45.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.19</td>\n",
       "      <td>4.57</td>\n",
       "      <td>42.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.21</td>\n",
       "      <td>3.93</td>\n",
       "      <td>53.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>4.60</td>\n",
       "      <td>68.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">ap_fixed&lt;16, 6&gt;</th>\n",
       "      <th>1</th>\n",
       "      <td>0.24</td>\n",
       "      <td>39.61</td>\n",
       "      <td>0.42</td>\n",
       "      <td>8.85</td>\n",
       "      <td>47.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.21</td>\n",
       "      <td>25.37</td>\n",
       "      <td>0.48</td>\n",
       "      <td>9.35</td>\n",
       "      <td>53.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.16</td>\n",
       "      <td>12.97</td>\n",
       "      <td>0.62</td>\n",
       "      <td>9.48</td>\n",
       "      <td>58.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.08</td>\n",
       "      <td>6.57</td>\n",
       "      <td>0.86</td>\n",
       "      <td>9.52</td>\n",
       "      <td>76.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.19</td>\n",
       "      <td>2.74</td>\n",
       "      <td>1.27</td>\n",
       "      <td>9.71</td>\n",
       "      <td>111.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.48</td>\n",
       "      <td>1.81</td>\n",
       "      <td>1.47</td>\n",
       "      <td>9.03</td>\n",
       "      <td>114.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.10</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.45</td>\n",
       "      <td>8.64</td>\n",
       "      <td>195.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"21\" valign=\"top\">Resource</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">ap_fixed&lt;2, 1&gt;</th>\n",
       "      <th>1</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>61.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.22</td>\n",
       "      <td>6.10</td>\n",
       "      <td>64.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.23</td>\n",
       "      <td>6.91</td>\n",
       "      <td>72.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.22</td>\n",
       "      <td>3.58</td>\n",
       "      <td>89.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>91.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.41</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.66</td>\n",
       "      <td>176.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>283.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">ap_fixed&lt;8, 3&gt;</th>\n",
       "      <th>1</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.26</td>\n",
       "      <td>6.93</td>\n",
       "      <td>54.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.27</td>\n",
       "      <td>19.41</td>\n",
       "      <td>59.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.29</td>\n",
       "      <td>21.24</td>\n",
       "      <td>60.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>12.64</td>\n",
       "      <td>76.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.37</td>\n",
       "      <td>7.39</td>\n",
       "      <td>137.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.43</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.34</td>\n",
       "      <td>2.02</td>\n",
       "      <td>164.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.19</td>\n",
       "      <td>2.56</td>\n",
       "      <td>291.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">ap_fixed&lt;16, 6&gt;</th>\n",
       "      <th>1</th>\n",
       "      <td>2.06</td>\n",
       "      <td>39.82</td>\n",
       "      <td>0.32</td>\n",
       "      <td>12.43</td>\n",
       "      <td>59.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.51</td>\n",
       "      <td>25.47</td>\n",
       "      <td>0.33</td>\n",
       "      <td>17.46</td>\n",
       "      <td>61.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.39</td>\n",
       "      <td>13.02</td>\n",
       "      <td>0.37</td>\n",
       "      <td>16.43</td>\n",
       "      <td>67.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.24</td>\n",
       "      <td>6.59</td>\n",
       "      <td>0.43</td>\n",
       "      <td>10.71</td>\n",
       "      <td>96.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.46</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.54</td>\n",
       "      <td>6.80</td>\n",
       "      <td>148.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.73</td>\n",
       "      <td>1.81</td>\n",
       "      <td>0.49</td>\n",
       "      <td>3.55</td>\n",
       "      <td>212.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.67</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.64</td>\n",
       "      <td>3.60</td>\n",
       "      <td>341.34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 BRAM (%)  \\\n",
       "Model          Board      Strategy Precision       Reuse Factor             \n",
       "Jet Classifier pynq-z2    Latency  ap_fixed<2, 1>  1                 2.77   \n",
       "                                                   2                 2.75   \n",
       "                                                   4                 2.70   \n",
       "                                                   8                 2.97   \n",
       "                                                   16                2.97   \n",
       "                                                   32                2.26   \n",
       "                                                   64                0.83   \n",
       "                                   ap_fixed<8, 3>  1                 2.63   \n",
       "                                                   2                 2.63   \n",
       "                                                   4                 2.59   \n",
       "                                                   8                 2.76   \n",
       "                                                   16                3.42   \n",
       "                                                   32                2.99   \n",
       "                                                   64                0.56   \n",
       "                                   ap_fixed<16, 6> 1                 1.78   \n",
       "                                                   2                 2.30   \n",
       "                                                   4                 2.38   \n",
       "                                                   8                 1.48   \n",
       "                                                   16                2.90   \n",
       "                                                   32                4.43   \n",
       "                                                   64                0.75   \n",
       "                          Resource ap_fixed<2, 1>  1                 5.67   \n",
       "                                                   2                34.49   \n",
       "                                                   4                13.99   \n",
       "                                                   8                10.20   \n",
       "                                                   16                7.84   \n",
       "                                                   32                4.20   \n",
       "                                                   64                3.44   \n",
       "                                   ap_fixed<8, 3>  1                10.05   \n",
       "                                                   2                55.80   \n",
       "                                                   4                55.67   \n",
       "                                                   8                20.88   \n",
       "                                                   16               11.99   \n",
       "                                                   32                5.06   \n",
       "                                                   64                3.01   \n",
       "                                   ap_fixed<16, 6> 1                11.69   \n",
       "                                                   2               119.10   \n",
       "                                                   4                89.59   \n",
       "                                                   8                47.71   \n",
       "                                                   16               27.98   \n",
       "                                                   32                9.69   \n",
       "                                                   64                5.45   \n",
       "               zcu102     Latency  ap_fixed<2, 1>  1                 0.71   \n",
       "                                                   2                 0.71   \n",
       "                                                   4                 0.75   \n",
       "                                                   8                 0.84   \n",
       "                                                   16                0.81   \n",
       "                                                   32                0.38   \n",
       "                                                   64                0.54   \n",
       "                                   ap_fixed<8, 3>  1                 0.57   \n",
       "                                                   2                 0.54   \n",
       "                                                   4                 0.48   \n",
       "                                                   8                 0.47   \n",
       "                                                   16                0.72   \n",
       "                                                   32                0.62   \n",
       "                                                   64                0.55   \n",
       "                                   ap_fixed<16, 6> 1                 0.65   \n",
       "                                                   2                 0.62   \n",
       "                                                   4                 0.58   \n",
       "                                                   8                 0.50   \n",
       "                                                   16                0.63   \n",
       "                                                   32                0.65   \n",
       "                                                   64                0.48   \n",
       "                          Resource ap_fixed<2, 1>  1                 1.60   \n",
       "                                                   2                 3.81   \n",
       "                                                   4                 2.68   \n",
       "                                                   8                 1.11   \n",
       "                                                   16                0.85   \n",
       "                                                   32                0.74   \n",
       "                                                   64                0.73   \n",
       "                                   ap_fixed<8, 3>  1                 2.04   \n",
       "                                                   2                12.17   \n",
       "                                                   4                 6.98   \n",
       "                                                   8                 5.40   \n",
       "                                                   16                1.46   \n",
       "                                                   32                0.94   \n",
       "                                                   64                0.77   \n",
       "                                   ap_fixed<16, 6> 1                 2.25   \n",
       "                                                   2                32.38   \n",
       "                                                   4                21.17   \n",
       "                                                   8                11.52   \n",
       "                                                   16                5.19   \n",
       "                                                   32                1.55   \n",
       "                                                   64                0.91   \n",
       "               alveo-u200 Latency  ap_fixed<2, 1>  1                 0.81   \n",
       "                                                   2                 0.83   \n",
       "                                                   4                 0.84   \n",
       "                                                   8                 0.83   \n",
       "                                                   16                0.85   \n",
       "                                                   32                0.41   \n",
       "                                                   64                0.30   \n",
       "                                   ap_fixed<8, 3>  1                 0.42   \n",
       "                                                   2                 0.39   \n",
       "                                                   4                 0.33   \n",
       "                                                   8                 0.42   \n",
       "                                                   16                0.56   \n",
       "                                                   32                0.36   \n",
       "                                                   64                0.15   \n",
       "                                   ap_fixed<16, 6> 1                 0.24   \n",
       "                                                   2                 0.21   \n",
       "                                                   4                 0.16   \n",
       "                                                   8                 0.08   \n",
       "                                                   16                0.19   \n",
       "                                                   32                0.48   \n",
       "                                                   64                0.10   \n",
       "                          Resource ap_fixed<2, 1>  1                 0.78   \n",
       "                                                   2                 1.32   \n",
       "                                                   4                 1.11   \n",
       "                                                   8                 0.77   \n",
       "                                                   16                0.49   \n",
       "                                                   32                0.41   \n",
       "                                                   64                0.45   \n",
       "                                   ap_fixed<8, 3>  1                 0.86   \n",
       "                                                   2                 3.56   \n",
       "                                                   4                 2.46   \n",
       "                                                   8                 1.39   \n",
       "                                                   16                0.51   \n",
       "                                                   32                0.43   \n",
       "                                                   64                0.49   \n",
       "                                   ap_fixed<16, 6> 1                 2.06   \n",
       "                                                   2                 5.51   \n",
       "                                                   4                 4.39   \n",
       "                                                   8                 2.24   \n",
       "                                                   16                1.46   \n",
       "                                                   32                0.73   \n",
       "                                                   64                0.67   \n",
       "\n",
       "                                                                 DSP (%)  \\\n",
       "Model          Board      Strategy Precision       Reuse Factor            \n",
       "Jet Classifier pynq-z2    Latency  ap_fixed<2, 1>  1                0.89   \n",
       "                                                   2                0.86   \n",
       "                                                   4                0.79   \n",
       "                                                   8                0.67   \n",
       "                                                   16               0.63   \n",
       "                                                   32               0.74   \n",
       "                                                   64               0.47   \n",
       "                                   ap_fixed<8, 3>  1                1.58   \n",
       "                                                   2                1.50   \n",
       "                                                   4                1.25   \n",
       "                                                   8                1.41   \n",
       "                                                   16               1.96   \n",
       "                                                   32               1.93   \n",
       "                                                   64               1.70   \n",
       "                                   ap_fixed<16, 6> 1              199.86   \n",
       "                                                   2              198.30   \n",
       "                                                   4              198.50   \n",
       "                                                   8              175.18   \n",
       "                                                   16              83.85   \n",
       "                                                   32              51.04   \n",
       "                                                   64              30.32   \n",
       "                          Resource ap_fixed<2, 1>  1                0.90   \n",
       "                                                   2                0.89   \n",
       "                                                   4                0.82   \n",
       "                                                   8                0.69   \n",
       "                                                   16               0.66   \n",
       "                                                   32               0.77   \n",
       "                                                   64               0.48   \n",
       "                                   ap_fixed<8, 3>  1                1.60   \n",
       "                                                   2                1.52   \n",
       "                                                   4                1.27   \n",
       "                                                   8                1.43   \n",
       "                                                   16               2.00   \n",
       "                                                   32               1.98   \n",
       "                                                   64               1.75   \n",
       "                                   ap_fixed<16, 6> 1              199.97   \n",
       "                                                   2              198.44   \n",
       "                                                   4              198.63   \n",
       "                                                   8              175.83   \n",
       "                                                   16              84.48   \n",
       "                                                   32              51.36   \n",
       "                                                   64              30.57   \n",
       "               zcu102     Latency  ap_fixed<2, 1>  1                0.00   \n",
       "                                                   2                0.00   \n",
       "                                                   4                0.00   \n",
       "                                                   8                0.00   \n",
       "                                                   16               0.00   \n",
       "                                                   32               0.00   \n",
       "                                                   64               0.00   \n",
       "                                   ap_fixed<8, 3>  1                0.00   \n",
       "                                                   2                0.00   \n",
       "                                                   4                0.00   \n",
       "                                                   8                0.00   \n",
       "                                                   16               0.00   \n",
       "                                                   32               0.00   \n",
       "                                                   64               0.00   \n",
       "                                   ap_fixed<16, 6> 1              109.08   \n",
       "                                                   2               75.48   \n",
       "                                                   4               35.35   \n",
       "                                                   8               17.65   \n",
       "                                                   16               7.18   \n",
       "                                                   32               4.68   \n",
       "                                                   64               3.02   \n",
       "                          Resource ap_fixed<2, 1>  1                0.00   \n",
       "                                                   2                0.00   \n",
       "                                                   4                0.00   \n",
       "                                                   8                0.00   \n",
       "                                                   16               0.00   \n",
       "                                                   32               0.00   \n",
       "                                                   64               0.00   \n",
       "                                   ap_fixed<8, 3>  1                0.00   \n",
       "                                                   2                0.00   \n",
       "                                                   4                0.00   \n",
       "                                                   8                0.00   \n",
       "                                                   16               0.00   \n",
       "                                                   32               0.00   \n",
       "                                                   64               0.00   \n",
       "                                   ap_fixed<16, 6> 1              109.62   \n",
       "                                                   2               75.81   \n",
       "                                                   4               35.48   \n",
       "                                                   8               17.76   \n",
       "                                                   16               7.22   \n",
       "                                                   32               4.71   \n",
       "                                                   64               3.03   \n",
       "               alveo-u200 Latency  ap_fixed<2, 1>  1                0.00   \n",
       "                                                   2                0.00   \n",
       "                                                   4                0.00   \n",
       "                                                   8                0.00   \n",
       "                                                   16               0.00   \n",
       "                                                   32               0.00   \n",
       "                                                   64               0.00   \n",
       "                                   ap_fixed<8, 3>  1                0.00   \n",
       "                                                   2                0.00   \n",
       "                                                   4                0.00   \n",
       "                                                   8                0.00   \n",
       "                                                   16               0.00   \n",
       "                                                   32               0.00   \n",
       "                                                   64               0.00   \n",
       "                                   ap_fixed<16, 6> 1               39.61   \n",
       "                                                   2               25.37   \n",
       "                                                   4               12.97   \n",
       "                                                   8                6.57   \n",
       "                                                   16               2.74   \n",
       "                                                   32               1.81   \n",
       "                                                   64               1.25   \n",
       "                          Resource ap_fixed<2, 1>  1                0.00   \n",
       "                                                   2                0.00   \n",
       "                                                   4                0.00   \n",
       "                                                   8                0.00   \n",
       "                                                   16               0.00   \n",
       "                                                   32               0.00   \n",
       "                                                   64               0.00   \n",
       "                                   ap_fixed<8, 3>  1                0.00   \n",
       "                                                   2                0.00   \n",
       "                                                   4                0.00   \n",
       "                                                   8                0.00   \n",
       "                                                   16               0.00   \n",
       "                                                   32               0.00   \n",
       "                                                   64               0.00   \n",
       "                                   ap_fixed<16, 6> 1               39.82   \n",
       "                                                   2               25.47   \n",
       "                                                   4               13.02   \n",
       "                                                   8                6.59   \n",
       "                                                   16               2.76   \n",
       "                                                   32               1.81   \n",
       "                                                   64               1.25   \n",
       "\n",
       "                                                                 FF (%)  \\\n",
       "Model          Board      Strategy Precision       Reuse Factor           \n",
       "Jet Classifier pynq-z2    Latency  ap_fixed<2, 1>  1               2.63   \n",
       "                                                   2               2.62   \n",
       "                                                   4               2.58   \n",
       "                                                   8               2.49   \n",
       "                                                   16              2.50   \n",
       "                                                   32              2.43   \n",
       "                                                   64              2.19   \n",
       "                                   ap_fixed<8, 3>  1              13.91   \n",
       "                                                   2              13.63   \n",
       "                                                   4              13.07   \n",
       "                                                   8              12.22   \n",
       "                                                   16             11.98   \n",
       "                                                   32             12.74   \n",
       "                                                   64             14.74   \n",
       "                                   ap_fixed<16, 6> 1              45.96   \n",
       "                                                   2              45.71   \n",
       "                                                   4              45.95   \n",
       "                                                   8              46.42   \n",
       "                                                   16             48.13   \n",
       "                                                   32             51.83   \n",
       "                                                   64             55.36   \n",
       "                          Resource ap_fixed<2, 1>  1               4.57   \n",
       "                                                   2               4.56   \n",
       "                                                   4               4.60   \n",
       "                                                   8               4.85   \n",
       "                                                   16              5.28   \n",
       "                                                   32              4.46   \n",
       "                                                   64              3.94   \n",
       "                                   ap_fixed<8, 3>  1              23.77   \n",
       "                                                   2              22.87   \n",
       "                                                   4              20.98   \n",
       "                                                   8              18.04   \n",
       "                                                   16             15.51   \n",
       "                                                   32             11.13   \n",
       "                                                   64              9.30   \n",
       "                                   ap_fixed<16, 6> 1              59.83   \n",
       "                                                   2              57.58   \n",
       "                                                   4              52.50   \n",
       "                                                   8              43.00   \n",
       "                                                   16             29.85   \n",
       "                                                   32             20.54   \n",
       "                                                   64             15.79   \n",
       "               zcu102     Latency  ap_fixed<2, 1>  1               0.16   \n",
       "                                                   2               0.17   \n",
       "                                                   4               0.19   \n",
       "                                                   8               0.21   \n",
       "                                                   16              0.12   \n",
       "                                                   32              0.00   \n",
       "                                                   64              0.01   \n",
       "                                   ap_fixed<8, 3>  1               0.17   \n",
       "                                                   2               0.20   \n",
       "                                                   4               0.23   \n",
       "                                                   8               0.30   \n",
       "                                                   16              0.47   \n",
       "                                                   32              0.68   \n",
       "                                                   64              0.88   \n",
       "                                   ap_fixed<16, 6> 1               1.75   \n",
       "                                                   2               1.94   \n",
       "                                                   4               2.35   \n",
       "                                                   8               3.13   \n",
       "                                                   16              4.57   \n",
       "                                                   32              5.85   \n",
       "                                                   64              6.33   \n",
       "                          Resource ap_fixed<2, 1>  1               0.53   \n",
       "                                                   2               0.52   \n",
       "                                                   4               0.49   \n",
       "                                                   8               0.40   \n",
       "                                                   16              0.33   \n",
       "                                                   32              0.33   \n",
       "                                                   64              0.40   \n",
       "                                   ap_fixed<8, 3>  1               0.93   \n",
       "                                                   2               0.96   \n",
       "                                                   4               1.02   \n",
       "                                                   8               1.14   \n",
       "                                                   16              1.22   \n",
       "                                                   32              1.27   \n",
       "                                                   64              1.28   \n",
       "                                   ap_fixed<16, 6> 1               1.69   \n",
       "                                                   2               1.78   \n",
       "                                                   4               1.95   \n",
       "                                                   8               2.12   \n",
       "                                                   16              2.27   \n",
       "                                                   32              2.40   \n",
       "                                                   64              2.23   \n",
       "               alveo-u200 Latency  ap_fixed<2, 1>  1               0.00   \n",
       "                                                   2               0.00   \n",
       "                                                   4               0.00   \n",
       "                                                   8               0.00   \n",
       "                                                   16              0.00   \n",
       "                                                   32              0.00   \n",
       "                                                   64              0.00   \n",
       "                                   ap_fixed<8, 3>  1               0.16   \n",
       "                                                   2               0.17   \n",
       "                                                   4               0.18   \n",
       "                                                   8               0.19   \n",
       "                                                   16              0.19   \n",
       "                                                   32              0.21   \n",
       "                                                   64              0.17   \n",
       "                                   ap_fixed<16, 6> 1               0.42   \n",
       "                                                   2               0.48   \n",
       "                                                   4               0.62   \n",
       "                                                   8               0.86   \n",
       "                                                   16              1.27   \n",
       "                                                   32              1.47   \n",
       "                                                   64              1.45   \n",
       "                          Resource ap_fixed<2, 1>  1               0.22   \n",
       "                                                   2               0.22   \n",
       "                                                   4               0.23   \n",
       "                                                   8               0.22   \n",
       "                                                   16              0.20   \n",
       "                                                   32              0.17   \n",
       "                                                   64              0.16   \n",
       "                                   ap_fixed<8, 3>  1               0.26   \n",
       "                                                   2               0.27   \n",
       "                                                   4               0.29   \n",
       "                                                   8               0.31   \n",
       "                                                   16              0.37   \n",
       "                                                   32              0.34   \n",
       "                                                   64              0.19   \n",
       "                                   ap_fixed<16, 6> 1               0.32   \n",
       "                                                   2               0.33   \n",
       "                                                   4               0.37   \n",
       "                                                   8               0.43   \n",
       "                                                   16              0.54   \n",
       "                                                   32              0.49   \n",
       "                                                   64              0.64   \n",
       "\n",
       "                                                                 LUT (%)  \\\n",
       "Model          Board      Strategy Precision       Reuse Factor            \n",
       "Jet Classifier pynq-z2    Latency  ap_fixed<2, 1>  1               30.02   \n",
       "                                                   2               29.91   \n",
       "                                                   4               29.80   \n",
       "                                                   8               29.79   \n",
       "                                                   16              30.24   \n",
       "                                                   32              30.90   \n",
       "                                                   64              32.89   \n",
       "                                   ap_fixed<8, 3>  1              115.89   \n",
       "                                                   2              111.75   \n",
       "                                                   4              108.52   \n",
       "                                                   8              108.01   \n",
       "                                                   16             104.58   \n",
       "                                                   32              94.71   \n",
       "                                                   64              92.78   \n",
       "                                   ap_fixed<16, 6> 1              184.86   \n",
       "                                                   2              190.51   \n",
       "                                                   4              195.05   \n",
       "                                                   8              188.65   \n",
       "                                                   16             184.96   \n",
       "                                                   32             193.38   \n",
       "                                                   64             193.26   \n",
       "                          Resource ap_fixed<2, 1>  1               76.14   \n",
       "                                                   2              149.70   \n",
       "                                                   4              174.11   \n",
       "                                                   8              139.49   \n",
       "                                                   16              70.91   \n",
       "                                                   32              39.63   \n",
       "                                                   64              45.27   \n",
       "                                   ap_fixed<8, 3>  1              141.49   \n",
       "                                                   2              183.85   \n",
       "                                                   4              198.83   \n",
       "                                                   8              165.30   \n",
       "                                                   16             115.64   \n",
       "                                                   32              72.22   \n",
       "                                                   64              67.29   \n",
       "                                   ap_fixed<16, 6> 1              187.63   \n",
       "                                                   2              195.18   \n",
       "                                                   4              197.65   \n",
       "                                                   8              196.30   \n",
       "                                                   16             145.65   \n",
       "                                                   32             116.51   \n",
       "                                                   64             117.74   \n",
       "               zcu102     Latency  ap_fixed<2, 1>  1                7.57   \n",
       "                                                   2                7.47   \n",
       "                                                   4                7.50   \n",
       "                                                   8                7.17   \n",
       "                                                   16               5.87   \n",
       "                                                   32               4.53   \n",
       "                                                   64               6.98   \n",
       "                                   ap_fixed<8, 3>  1               26.85   \n",
       "                                                   2               26.28   \n",
       "                                                   4               26.49   \n",
       "                                                   8               26.13   \n",
       "                                                   16              25.94   \n",
       "                                                   32              25.22   \n",
       "                                                   64              23.51   \n",
       "                                   ap_fixed<16, 6> 1               47.02   \n",
       "                                                   2               48.70   \n",
       "                                                   4               50.72   \n",
       "                                                   8               48.29   \n",
       "                                                   16              48.69   \n",
       "                                                   32              49.10   \n",
       "                                                   64              40.80   \n",
       "                          Resource ap_fixed<2, 1>  1                8.82   \n",
       "                                                   2               30.46   \n",
       "                                                   4               31.68   \n",
       "                                                   8               29.44   \n",
       "                                                   16              18.45   \n",
       "                                                   32              12.30   \n",
       "                                                   64               9.21   \n",
       "                                   ap_fixed<8, 3>  1               26.10   \n",
       "                                                   2               54.43   \n",
       "                                                   4               72.25   \n",
       "                                                   8               48.05   \n",
       "                                                   16              28.90   \n",
       "                                                   32              14.83   \n",
       "                                                   64              14.77   \n",
       "                                   ap_fixed<16, 6> 1               52.05   \n",
       "                                                   2               73.82   \n",
       "                                                   4               89.13   \n",
       "                                                   8               58.20   \n",
       "                                                   16              31.63   \n",
       "                                                   32              20.12   \n",
       "                                                   64              21.29   \n",
       "               alveo-u200 Latency  ap_fixed<2, 1>  1                0.75   \n",
       "                                                   2                0.53   \n",
       "                                                   4                0.67   \n",
       "                                                   8                0.68   \n",
       "                                                   16               1.07   \n",
       "                                                   32               0.00   \n",
       "                                                   64               0.00   \n",
       "                                   ap_fixed<8, 3>  1                4.02   \n",
       "                                                   2                4.05   \n",
       "                                                   4                4.30   \n",
       "                                                   8                4.34   \n",
       "                                                   16               4.57   \n",
       "                                                   32               3.93   \n",
       "                                                   64               4.60   \n",
       "                                   ap_fixed<16, 6> 1                8.85   \n",
       "                                                   2                9.35   \n",
       "                                                   4                9.48   \n",
       "                                                   8                9.52   \n",
       "                                                   16               9.71   \n",
       "                                                   32               9.03   \n",
       "                                                   64               8.64   \n",
       "                          Resource ap_fixed<2, 1>  1                0.00   \n",
       "                                                   2                6.10   \n",
       "                                                   4                6.91   \n",
       "                                                   8                3.58   \n",
       "                                                   16               0.00   \n",
       "                                                   32               0.66   \n",
       "                                                   64               0.00   \n",
       "                                   ap_fixed<8, 3>  1                6.93   \n",
       "                                                   2               19.41   \n",
       "                                                   4               21.24   \n",
       "                                                   8               12.64   \n",
       "                                                   16               7.39   \n",
       "                                                   32               2.02   \n",
       "                                                   64               2.56   \n",
       "                                   ap_fixed<16, 6> 1               12.43   \n",
       "                                                   2               17.46   \n",
       "                                                   4               16.43   \n",
       "                                                   8               10.71   \n",
       "                                                   16               6.80   \n",
       "                                                   32               3.55   \n",
       "                                                   64               3.60   \n",
       "\n",
       "                                                                 CYCLES  \n",
       "Model          Board      Strategy Precision       Reuse Factor          \n",
       "Jet Classifier pynq-z2    Latency  ap_fixed<2, 1>  1              54.68  \n",
       "                                                   2              55.84  \n",
       "                                                   4              55.78  \n",
       "                                                   8              68.84  \n",
       "                                                   16             75.38  \n",
       "                                                   32             76.19  \n",
       "                                                   64            112.04  \n",
       "                                   ap_fixed<8, 3>  1              53.96  \n",
       "                                                   2              54.70  \n",
       "                                                   4              56.16  \n",
       "                                                   8              53.07  \n",
       "                                                   16             64.71  \n",
       "                                                   32             83.06  \n",
       "                                                   64            104.88  \n",
       "                                   ap_fixed<16, 6> 1              66.59  \n",
       "                                                   2              68.14  \n",
       "                                                   4              73.15  \n",
       "                                                   8              95.70  \n",
       "                                                   16            101.44  \n",
       "                                                   32            141.07  \n",
       "                                                   64            229.37  \n",
       "                          Resource ap_fixed<2, 1>  1              75.22  \n",
       "                                                   2              78.89  \n",
       "                                                   4              89.72  \n",
       "                                                   8             111.75  \n",
       "                                                   16            132.12  \n",
       "                                                   32            208.69  \n",
       "                                                   64            304.05  \n",
       "                                   ap_fixed<8, 3>  1              68.06  \n",
       "                                                   2              73.07  \n",
       "                                                   4              77.51  \n",
       "                                                   8              97.81  \n",
       "                                                   16            159.26  \n",
       "                                                   32            187.69  \n",
       "                                                   64            333.98  \n",
       "                                   ap_fixed<16, 6> 1              75.57  \n",
       "                                                   2              75.91  \n",
       "                                                   4              83.27  \n",
       "                                                   8             122.93  \n",
       "                                                   16            195.46  \n",
       "                                                   32            239.00  \n",
       "                                                   64            361.06  \n",
       "               zcu102     Latency  ap_fixed<2, 1>  1              36.51  \n",
       "                                                   2              37.45  \n",
       "                                                   4              41.43  \n",
       "                                                   8              54.65  \n",
       "                                                   16             55.57  \n",
       "                                                   32             51.70  \n",
       "                                                   64            106.39  \n",
       "                                   ap_fixed<8, 3>  1              41.56  \n",
       "                                                   2              42.61  \n",
       "                                                   4              44.76  \n",
       "                                                   8              46.50  \n",
       "                                                   16             45.63  \n",
       "                                                   32             56.56  \n",
       "                                                   64             74.10  \n",
       "                                   ap_fixed<16, 6> 1              48.31  \n",
       "                                                   2              54.69  \n",
       "                                                   4              59.01  \n",
       "                                                   8              76.58  \n",
       "                                                   16            109.89  \n",
       "                                                   32            115.60  \n",
       "                                                   64            200.85  \n",
       "                          Resource ap_fixed<2, 1>  1              61.64  \n",
       "                                                   2              64.96  \n",
       "                                                   4              74.60  \n",
       "                                                   8              92.17  \n",
       "                                                   16             91.11  \n",
       "                                                   32            182.08  \n",
       "                                                   64            288.58  \n",
       "                                   ap_fixed<8, 3>  1              55.23  \n",
       "                                                   2              59.48  \n",
       "                                                   4              62.33  \n",
       "                                                   8              78.71  \n",
       "                                                   16            141.35  \n",
       "                                                   32            179.51  \n",
       "                                                   64            296.61  \n",
       "                                   ap_fixed<16, 6> 1              61.63  \n",
       "                                                   2              63.53  \n",
       "                                                   4              68.18  \n",
       "                                                   8              98.30  \n",
       "                                                   16            153.89  \n",
       "                                                   32            215.93  \n",
       "                                                   64            347.91  \n",
       "               alveo-u200 Latency  ap_fixed<2, 1>  1              37.91  \n",
       "                                                   2              35.80  \n",
       "                                                   4              37.74  \n",
       "                                                   8              53.28  \n",
       "                                                   16             54.17  \n",
       "                                                   32             51.97  \n",
       "                                                   64            109.17  \n",
       "                                   ap_fixed<8, 3>  1              41.68  \n",
       "                                                   2              43.37  \n",
       "                                                   4              44.61  \n",
       "                                                   8              45.71  \n",
       "                                                   16             42.68  \n",
       "                                                   32             53.96  \n",
       "                                                   64             68.71  \n",
       "                                   ap_fixed<16, 6> 1              47.30  \n",
       "                                                   2              53.96  \n",
       "                                                   4              58.21  \n",
       "                                                   8              76.48  \n",
       "                                                   16            111.29  \n",
       "                                                   32            114.66  \n",
       "                                                   64            195.29  \n",
       "                          Resource ap_fixed<2, 1>  1              61.10  \n",
       "                                                   2              64.01  \n",
       "                                                   4              72.46  \n",
       "                                                   8              89.42  \n",
       "                                                   16             91.14  \n",
       "                                                   32            176.23  \n",
       "                                                   64            283.55  \n",
       "                                   ap_fixed<8, 3>  1              54.84  \n",
       "                                                   2              59.33  \n",
       "                                                   4              60.40  \n",
       "                                                   8              76.54  \n",
       "                                                   16            137.63  \n",
       "                                                   32            164.63  \n",
       "                                                   64            291.64  \n",
       "                                   ap_fixed<16, 6> 1              59.63  \n",
       "                                                   2              61.36  \n",
       "                                                   4              67.35  \n",
       "                                                   8              96.51  \n",
       "                                                   16            148.54  \n",
       "                                                   32            212.15  \n",
       "                                                   64            341.34  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MultiModelEstimator predictions are formatted as a DataFrame\n",
    "prediction_df = estimator.predict(model_to_predict, verbose=1)\n",
    "\n",
    "# each row is unique in the groupby, mean() is only called to convert DataFrameGroupBy into a neatly organized DataFrame\n",
    "if not prediction_df.empty:\n",
    "    prediction_df = prediction_df.groupby(\n",
    "        [\"Model\", \"Board\", \"Strategy\", \"Precision\", \"Reuse Factor\"], observed=True\n",
    "    ).mean()\n",
    "\n",
    "prediction_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`MultiModelEstimator` returns a pandas `DataFrame`, giving access to many useful operations (min, max, groupby, where, etc.)\n",
    "\n",
    "The prediction dataframe can be exported in various formats as well. We recommend saving as HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df.to_html(\"keras_example.html\")\n",
    "\n",
    "# prediction_df.to_latex(\"keras_example.tex\")\n",
    "# prediction_df.to_csv(\"keras_example.csv\")\n",
    "# prediction_df.to_json(\"keras_example.json\")\n",
    "# prediction_df.to_xml(\"keras_example.xml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Advanced Usage <a class=\"anchor\" id=\"advanced-usage\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we explore alternative and more flexible ways to load weights and make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "import keras\n",
    "from keras.layers import Input, Dense\n",
    "import torch\n",
    "\n",
    "models_to_predict = []\n",
    "\n",
    "\n",
    "# Example of a subclassed PyTorch model\n",
    "class MyTopQuarks(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyTopQuarks, self).__init__()\n",
    "\n",
    "        self.dense1 = torch.nn.Linear(10, 32)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.dense2 = torch.nn.Linear(32, 1)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.dense1(inputs)\n",
    "        x = self.relu(x)\n",
    "        x = self.dense2(x)\n",
    "        outputs = self.sigmoid(x)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "\n",
    "models_to_predict.append(MyTopQuarks())\n",
    "\n",
    "# Example of a keras Sequential model\n",
    "input_size = 16\n",
    "model_to_predict = keras.Sequential(\n",
    "    layers=[\n",
    "        keras.layers.Input(shape=(input_size,)),\n",
    "        keras.layers.Dense(32, use_bias=True),\n",
    "        keras.layers.Activation(\"relu\"),\n",
    "        keras.layers.Dense(32, use_bias=True),\n",
    "        keras.layers.Activation(\"relu\"),\n",
    "        keras.layers.Dense(32, use_bias=True),\n",
    "        keras.layers.Activation(\"relu\"),\n",
    "        keras.layers.Dense(5, use_bias=True),\n",
    "        keras.layers.Activation(\"softmax\"),\n",
    "    ],\n",
    "    name=\"Jet Classifier\",\n",
    ")\n",
    "model_to_predict.build((None, input_size))\n",
    "\n",
    "models_to_predict.append(model_to_predict)\n",
    "\n",
    "# Instead of default configs, we can specify custom configurations we want to predict for\n",
    "hls_configs = [\n",
    "    {\n",
    "        \"model\": {\n",
    "            \"precision\": \"ap_fixed<8, 3>\",\n",
    "            \"reuse_factor\": 32,\n",
    "            \"strategy\": strategy,\n",
    "        },\n",
    "        \"board\": board,\n",
    "    }\n",
    "    for board, strategy in itertools.product([\"pynq-z2\", \"zcu102\"], [\"Latency\", \"Resource\"])\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the `ModelWrapper`, it's possible to load individual predictors. Let's say we're only interested in predicting **LUT** this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Model \"LUT_MLP\" does not support board \"alveo-u250\". Supported boards: ['pynq-z2', 'zcu102', 'alveo-u200']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m lut_model_wrapper \u001b[38;5;241m=\u001b[39m ModelWrapper()\n\u001b[1;32m      4\u001b[0m lut_model_wrapper\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./models/best_LUT_MLP_config.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./models/best_LUT_MLP.weights.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Load LUT predictor\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[43mlut_model_wrapper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodels_to_predict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhls_configs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# ModelWrapper returns an ndarray of predictions, one for each model/config combination\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/rule4ml/rule4ml/models/estimators.py:721\u001b[0m, in \u001b[0;36mModelWrapper.predict\u001b[0;34m(self, models_to_predict, hls_configs, verbose)\u001b[0m\n\u001b[1;32m    719\u001b[0m config_strategy \u001b[38;5;241m=\u001b[39m hls_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrategy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    720\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config_board\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m supported_boards:\n\u001b[0;32m--> 721\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    722\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m does not support board \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mconfig_board\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m. Supported boards: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(supported_boards\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    723\u001b[0m     )\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config_strategy\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m supported_strategies:\n\u001b[1;32m    725\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    726\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m does not support strategy \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mconfig_strategy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m. Supported strategies: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(supported_strategies\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    727\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Model \"LUT_MLP\" does not support board \"alveo-u250\". Supported boards: ['pynq-z2', 'zcu102', 'alveo-u200']"
     ]
    }
   ],
   "source": [
    "from rule4ml.models.estimators import ModelWrapper\n",
    "\n",
    "lut_model_wrapper = ModelWrapper()\n",
    "lut_model_wrapper.load(\n",
    "    \"./models/best_LUT_MLP_config.json\", \"./models/best_LUT_MLP.weights.h5\"\n",
    ")  # Load LUT predictor\n",
    "\n",
    "lut_model_wrapper.predict(\n",
    "    models_to_predict, hls_configs\n",
    ")  # ModelWrapper returns an ndarray of predictions, one for each model/config combination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can add the previous `ModelWrapper` to a new instance of `MultiModelEstimator` for a nicely formatted `DataFrame` output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Board",
         "rawType": "category",
         "type": "unknown"
        },
        {
         "name": "Strategy",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Precision",
         "rawType": "category",
         "type": "unknown"
        },
        {
         "name": "Reuse Factor",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "LUT (%)",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "e85c4973-3d74-4464-9e2d-4b0f8203193f",
       "rows": [
        [
         "0",
         "MyTopQuarks",
         "pynq-z2",
         "Latency",
         "ap_fixed<8, 3>",
         "32",
         "39.42"
        ],
        [
         "1",
         "MyTopQuarks",
         "pynq-z2",
         "Resource",
         "ap_fixed<8, 3>",
         "32",
         "51.59"
        ],
        [
         "2",
         "MyTopQuarks",
         "zcu102",
         "Latency",
         "ap_fixed<8, 3>",
         "32",
         "3.69"
        ],
        [
         "3",
         "MyTopQuarks",
         "zcu102",
         "Resource",
         "ap_fixed<8, 3>",
         "32",
         "6.61"
        ],
        [
         "4",
         "MyTopQuarks",
         "alveo-u200",
         "Latency",
         "ap_fixed<8, 3>",
         "32",
         "0.0"
        ],
        [
         "5",
         "MyTopQuarks",
         "alveo-u200",
         "Resource",
         "ap_fixed<8, 3>",
         "32",
         "0.42"
        ],
        [
         "6",
         "Jet Classifier",
         "pynq-z2",
         "Latency",
         "ap_fixed<8, 3>",
         "32",
         "94.71"
        ],
        [
         "7",
         "Jet Classifier",
         "pynq-z2",
         "Resource",
         "ap_fixed<8, 3>",
         "32",
         "72.22"
        ],
        [
         "8",
         "Jet Classifier",
         "zcu102",
         "Latency",
         "ap_fixed<8, 3>",
         "32",
         "25.22"
        ],
        [
         "9",
         "Jet Classifier",
         "zcu102",
         "Resource",
         "ap_fixed<8, 3>",
         "32",
         "14.83"
        ],
        [
         "10",
         "Jet Classifier",
         "alveo-u200",
         "Latency",
         "ap_fixed<8, 3>",
         "32",
         "3.93"
        ],
        [
         "11",
         "Jet Classifier",
         "alveo-u200",
         "Resource",
         "ap_fixed<8, 3>",
         "32",
         "2.02"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 12
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Board</th>\n",
       "      <th>Strategy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Reuse Factor</th>\n",
       "      <th>LUT (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MyTopQuarks</td>\n",
       "      <td>pynq-z2</td>\n",
       "      <td>Latency</td>\n",
       "      <td>ap_fixed&lt;8, 3&gt;</td>\n",
       "      <td>32</td>\n",
       "      <td>39.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MyTopQuarks</td>\n",
       "      <td>pynq-z2</td>\n",
       "      <td>Resource</td>\n",
       "      <td>ap_fixed&lt;8, 3&gt;</td>\n",
       "      <td>32</td>\n",
       "      <td>51.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MyTopQuarks</td>\n",
       "      <td>zcu102</td>\n",
       "      <td>Latency</td>\n",
       "      <td>ap_fixed&lt;8, 3&gt;</td>\n",
       "      <td>32</td>\n",
       "      <td>3.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MyTopQuarks</td>\n",
       "      <td>zcu102</td>\n",
       "      <td>Resource</td>\n",
       "      <td>ap_fixed&lt;8, 3&gt;</td>\n",
       "      <td>32</td>\n",
       "      <td>6.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MyTopQuarks</td>\n",
       "      <td>alveo-u200</td>\n",
       "      <td>Latency</td>\n",
       "      <td>ap_fixed&lt;8, 3&gt;</td>\n",
       "      <td>32</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MyTopQuarks</td>\n",
       "      <td>alveo-u200</td>\n",
       "      <td>Resource</td>\n",
       "      <td>ap_fixed&lt;8, 3&gt;</td>\n",
       "      <td>32</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Jet Classifier</td>\n",
       "      <td>pynq-z2</td>\n",
       "      <td>Latency</td>\n",
       "      <td>ap_fixed&lt;8, 3&gt;</td>\n",
       "      <td>32</td>\n",
       "      <td>94.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jet Classifier</td>\n",
       "      <td>pynq-z2</td>\n",
       "      <td>Resource</td>\n",
       "      <td>ap_fixed&lt;8, 3&gt;</td>\n",
       "      <td>32</td>\n",
       "      <td>72.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Jet Classifier</td>\n",
       "      <td>zcu102</td>\n",
       "      <td>Latency</td>\n",
       "      <td>ap_fixed&lt;8, 3&gt;</td>\n",
       "      <td>32</td>\n",
       "      <td>25.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Jet Classifier</td>\n",
       "      <td>zcu102</td>\n",
       "      <td>Resource</td>\n",
       "      <td>ap_fixed&lt;8, 3&gt;</td>\n",
       "      <td>32</td>\n",
       "      <td>14.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Jet Classifier</td>\n",
       "      <td>alveo-u200</td>\n",
       "      <td>Latency</td>\n",
       "      <td>ap_fixed&lt;8, 3&gt;</td>\n",
       "      <td>32</td>\n",
       "      <td>3.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Jet Classifier</td>\n",
       "      <td>alveo-u200</td>\n",
       "      <td>Resource</td>\n",
       "      <td>ap_fixed&lt;8, 3&gt;</td>\n",
       "      <td>32</td>\n",
       "      <td>2.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Model       Board  Strategy       Precision  Reuse Factor  \\\n",
       "0      MyTopQuarks     pynq-z2   Latency  ap_fixed<8, 3>            32   \n",
       "1      MyTopQuarks     pynq-z2  Resource  ap_fixed<8, 3>            32   \n",
       "2      MyTopQuarks      zcu102   Latency  ap_fixed<8, 3>            32   \n",
       "3      MyTopQuarks      zcu102  Resource  ap_fixed<8, 3>            32   \n",
       "4      MyTopQuarks  alveo-u200   Latency  ap_fixed<8, 3>            32   \n",
       "5      MyTopQuarks  alveo-u200  Resource  ap_fixed<8, 3>            32   \n",
       "6   Jet Classifier     pynq-z2   Latency  ap_fixed<8, 3>            32   \n",
       "7   Jet Classifier     pynq-z2  Resource  ap_fixed<8, 3>            32   \n",
       "8   Jet Classifier      zcu102   Latency  ap_fixed<8, 3>            32   \n",
       "9   Jet Classifier      zcu102  Resource  ap_fixed<8, 3>            32   \n",
       "10  Jet Classifier  alveo-u200   Latency  ap_fixed<8, 3>            32   \n",
       "11  Jet Classifier  alveo-u200  Resource  ap_fixed<8, 3>            32   \n",
       "\n",
       "    LUT (%)  \n",
       "0     39.42  \n",
       "1     51.59  \n",
       "2      3.69  \n",
       "3      6.61  \n",
       "4      0.00  \n",
       "5      0.42  \n",
       "6     94.71  \n",
       "7     72.22  \n",
       "8     25.22  \n",
       "9     14.83  \n",
       "10     3.93  \n",
       "11     2.02  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rule4ml.models.estimators import MultiModelEstimator\n",
    "\n",
    "estimator = MultiModelEstimator()\n",
    "estimator.add_model_wrapper(lut_model_wrapper)\n",
    "\n",
    "estimator.predict(models_to_predict, hls_configs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Generation <a class=\"anchor\" id=\"data-gen\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Specify Vivado path\n",
    "os.environ[\"PATH\"] = \"/opt/Xilinx/Vivado/2019.1/bin:\" + os.environ[\"PATH\"]\n",
    "\n",
    "base_path = os.path.join(os.getcwd(), \"..\", \"data_gen\")\n",
    "sys.path.append(base_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Model Synthesis <a class=\"anchor\" id=\"model-synth\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Keras Model <a class=\"anchor\" id=\"keras-synth\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "from data_gen.nn_synth import synthesize_keras_model\n",
    "\n",
    "input_size = 16\n",
    "inputs = Input(shape=(input_size,))\n",
    "x = Dense(32, activation=\"relu\")(inputs)\n",
    "x = Dense(32, activation=\"relu\")(x)\n",
    "x = Dense(32, activation=\"relu\")(x)\n",
    "outputs = Dense(5, activation=\"softmax\")(x)\n",
    "\n",
    "model_to_synthesize = keras.Model(inputs=inputs, outputs=outputs, name=\"Jet Classifier\")\n",
    "model_to_synthesize.build((None, input_size))\n",
    "\n",
    "synthesis_result = synthesize_keras_model(\n",
    "    model_to_synthesize,\n",
    "    board=\"pynq-z2\",\n",
    "    strategy=\"Resource\",\n",
    "    precision=\"ap_fixed<8, 3>\",\n",
    "    reuse_factor=32,\n",
    "    clock_period=\"10\",\n",
    "    io_type=\"io_parallel\",\n",
    "    project_dir=\"./hls4ml_prj\",\n",
    "    synth_uuid=None,\n",
    "    verbose=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_gen.utils import save_to_json\n",
    "\n",
    "save_to_json(synthesis_result, \"./synthesis_result.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 PyTorch Model <a class=\"anchor\" id=\"torch-synth\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from data_gen.nn_synth import synthesize_torch_model\n",
    "from data_gen.utils import save_to_json\n",
    "\n",
    "model_to_synthesize = torch.nn.Sequential(\n",
    "    torch.nn.Linear(10, 32),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(32, 1),\n",
    "    torch.nn.Sigmoid(),\n",
    ")\n",
    "\n",
    "synthesis_result = synthesize_torch_model(\n",
    "    model_to_synthesize,\n",
    "    board=\"zcu102\",\n",
    "    strategy=\"Latency\",\n",
    "    precision=\"ap_fixed<8, 3>\",\n",
    "    reuse_factor=32,\n",
    "    clock_period=\"10\",\n",
    "    io_type=\"io_parallel\",\n",
    "    project_dir=\"./hls4ml_prj\",\n",
    "    synth_uuid=None,\n",
    "    verbose=0,\n",
    ")\n",
    "\n",
    "save_to_json(synthesis_result, \"./synthesis_result.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Parallel Synthesis <a class=\"anchor\" id=\"parallel-synth\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Randomly Generated Networks <a class=\"anchor\" id=\"random-synth\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "import time\n",
    "\n",
    "from data_gen.nn_gen import GeneratorSettings, generate_fc_network\n",
    "from data_gen.nn_synth import (\n",
    "    SynthSettings,\n",
    "    synthesize_keras_model,\n",
    "    parallel_generative_synthesis,\n",
    ")\n",
    "\n",
    "from data_gen.utils import IntRange, Power2Range, save_to_json\n",
    "\n",
    "gen_settings = GeneratorSettings(\n",
    "    input_range=Power2Range(16, 32),\n",
    "    layer_range=IntRange(2, 3),\n",
    "    neuron_range=Power2Range(16, 32),\n",
    "    output_range=IntRange(1, 20),\n",
    "    activations=[\"relu\"],\n",
    ")\n",
    "synth_settings = SynthSettings(\n",
    "    reuse_range=Power2Range(32, 64),\n",
    "    precisions=[\"ap_fixed<2, 1>\", \"ap_fixed<8, 3>\"],\n",
    "    strategies=[\"Resource\"],\n",
    ")\n",
    "\n",
    "n_procs = 3\n",
    "with Pool(n_procs) as p:\n",
    "    result = p.map_async(\n",
    "        parallel_generative_synthesis,\n",
    "        [\n",
    "            {\n",
    "                \"job_id\": f\"{proc}\",\n",
    "                \"n_models\": 10,\n",
    "                \"project_dir\": \"./projects\",\n",
    "                \"prj_overwrite\": False,\n",
    "                \"save_path\": \"./\",\n",
    "                \"rng_seed\": 0,\n",
    "                \"gen_function\": generate_fc_network,  # Keras only currently\n",
    "                \"gen_settings\": gen_settings,\n",
    "                \"synth_function\": synthesize_keras_model,\n",
    "                \"synth_settings\": synth_settings,\n",
    "            }\n",
    "            for proc in range(1, n_procs + 1)\n",
    "        ],\n",
    "    )\n",
    "    while not result.ready():\n",
    "        time.sleep(1)\n",
    "    result = result.get()\n",
    "    p.terminate()\n",
    "    p.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Training Prediction Models <a class=\"anchor\" id=\"train-models\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Parsing Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 Reading from JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from rule4ml.parsers.data_parser import (\n",
    "#     read_from_json,\n",
    "#     ParsedDataFilter,\n",
    "#     get_global_data,\n",
    "#     get_sequential_data,\n",
    "#     to_dataframe,\n",
    "# )\n",
    "\n",
    "# from rule4ml.parsers.data_parser import (\n",
    "#     default_board_map,\n",
    "#     default_strategy_map,\n",
    "#     default_layer_type_map,\n",
    "# )\n",
    "\n",
    "# import json\n",
    "# from tqdm.auto import tqdm\n",
    "\n",
    "# base_path = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"datasets\", \"iccad_submit\"))\n",
    "# data_path = os.path.join(base_path, \"all_and_train_test_split\")\n",
    "\n",
    "# train_data = read_from_json(\n",
    "#     os.path.join(data_path, \"train_split.json\"),\n",
    "# )\n",
    "# train_data_split = []\n",
    "# for entry in tqdm(train_data):\n",
    "#     model_source = entry[\"type\"]\n",
    "#     json_name = entry[\"model_file\"].split(\".\")[0]\n",
    "#     if model_source != \"manylayer\":\n",
    "#         json_name = entry[\"model_name\"].split(\"/\")[-1]\n",
    "#         json_name += f\"_rf{entry['rf']}_processed\"\n",
    "\n",
    "#     json_path = os.path.join(base_path, \"preprocessed\", model_source, f\"{json_name}.json\")\n",
    "#     if not os.path.exists(json_path):\n",
    "#         continue\n",
    "\n",
    "#     data = read_from_json(json_path)\n",
    "#     if isinstance(data, dict):\n",
    "#         data = [data]\n",
    "\n",
    "#     for preprocessed_entry in data:\n",
    "#         preprocessed_entry[\"meta_data\"][\"model_type\"] = model_source\n",
    "#         train_data_split.append(preprocessed_entry)\n",
    "\n",
    "# train_file_path = os.path.join(base_path, \"preprocessed\", \"train_split.json\")\n",
    "# with open(train_file_path, \"w\") as json_file:\n",
    "#     json.dump(\n",
    "#         train_data_split,\n",
    "#         json_file,\n",
    "#         indent=2\n",
    "#     )\n",
    "\n",
    "\n",
    "# test_data = read_from_json(\n",
    "#     os.path.join(data_path, \"test_split.json\"),\n",
    "# )\n",
    "# test_data_split = []\n",
    "# for entry in tqdm(test_data):\n",
    "#     model_source = entry[\"type\"]\n",
    "#     json_name = entry[\"model_file\"].split(\".\")[0]\n",
    "#     if model_source != \"manylayer\":\n",
    "#         json_name = entry[\"model_name\"].split(\"/\")[-1]\n",
    "#         json_name += f\"_rf{entry['rf']}_processed\"\n",
    "\n",
    "#     json_path = os.path.join(base_path, \"preprocessed\", model_source, f\"{json_name}.json\")\n",
    "#     if not os.path.exists(json_path):\n",
    "#         continue\n",
    "\n",
    "#     data = read_from_json(json_path)\n",
    "#     if isinstance(data, dict):\n",
    "#         data = [data]\n",
    "\n",
    "#     for preprocessed_entry in data:\n",
    "#         preprocessed_entry[\"meta_data\"][\"model_type\"] = model_source\n",
    "#         test_data_split.append(preprocessed_entry)\n",
    "\n",
    "# test_file_path = os.path.join(base_path, \"preprocessed\", \"test_split.json\")\n",
    "# with open(test_file_path, \"w\") as json_file:\n",
    "#     json.dump(\n",
    "#         test_data_split,\n",
    "#         json_file,\n",
    "#         indent=2\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rule4ml.parsers.data_parser import (\n",
    "    read_from_json,\n",
    "    ParsedDataFilter,\n",
    "    get_global_data,\n",
    "    get_sequential_data,\n",
    "    to_dataframe,\n",
    ")\n",
    "\n",
    "from rule4ml.parsers.data_parser import (\n",
    "    default_board_map,\n",
    "    default_strategy_map,\n",
    "    default_layer_type_map,\n",
    ")\n",
    "\n",
    "# data_filter = ParsedDataFilter(\n",
    "#     max_output_size=200,\n",
    "# )\n",
    "\n",
    "base_path = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "# Ordinal encoding of categorical inputs\n",
    "global_categorical_maps = {\n",
    "    \"strategy\": default_strategy_map,\n",
    "    \"board\": default_board_map,\n",
    "}\n",
    "sequential_categorical_maps = {\n",
    "    \"layer_type\": default_layer_type_map,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_json_data = read_from_json(\n",
    "    os.path.join(base_path, \"datasets\", \"iccad_submit\", \"preprocessed\", \"train_split.json\"),\n",
    "    # data_filter,\n",
    ")\n",
    "\n",
    "train_meta_data, train_global_inputs, train_targets = get_global_data(train_json_data)\n",
    "train_sequential_inputs = get_sequential_data(train_json_data)\n",
    "\n",
    "train_df = to_dataframe(\n",
    "    meta_data=train_meta_data,\n",
    "    global_inputs=train_global_inputs,\n",
    "    sequential_inputs=train_sequential_inputs,\n",
    "    global_categorical_maps=global_categorical_maps,\n",
    "    sequential_categorical_maps=sequential_categorical_maps,\n",
    "    targets=train_targets,\n",
    ")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_json_data = read_from_json(\n",
    "    os.path.join(base_path, \"datasets\", \"iccad_submit\", \"preprocessed\", \"test_split.json\"),\n",
    "    # data_filter,\n",
    ")\n",
    "\n",
    "test_meta_data, test_global_inputs, test_targets = get_global_data(test_json_data)\n",
    "test_sequential_inputs = get_sequential_data(test_json_data)\n",
    "\n",
    "test_df = to_dataframe(\n",
    "    meta_data=test_meta_data,\n",
    "    global_inputs=test_global_inputs,\n",
    "    sequential_inputs=test_sequential_inputs,\n",
    "    global_categorical_maps=global_categorical_maps,\n",
    "    sequential_categorical_maps=sequential_categorical_maps,\n",
    "    targets=test_targets,\n",
    ")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.dropna(subset=[\"interval\"])\n",
    "test_df = test_df.dropna(subset=[\"interval\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams.update({\"font.size\": 32})\n",
    "\n",
    "target_labels = [\"bram\", \"dsp\", \"ff\", \"lut\", \"cycles\", \"interval\"]\n",
    "for target_label in target_labels:\n",
    "    train_df[target_label] = train_df[target_label].astype(int)\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "    ax.hist(train_df[target_label], bins=30, density=False, alpha=0.6, color=\"b\")\n",
    "    # ax.set_xlabel(target_label.upper())\n",
    "    ax.grid = True\n",
    "\n",
    "    fig.savefig(\n",
    "        f\"/mnt/c/Users/hamza/Downloads/{target_label.upper()}_hist.png\",\n",
    "        dpi=300,\n",
    "        bbox_extra_artists=(),\n",
    "        bbox_inches=\"tight\",\n",
    "    )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"sequential_inputs\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "seed_num = 1337\n",
    "np.random.seed(seed_num)\n",
    "keras.utils.set_random_seed(seed_num)\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "\n",
    "# train_df, test_df = train_test_split(df, test_size=0.05, random_state=seed_num)\n",
    "print(f\"Train Dataframe: {train_df.shape}\")\n",
    "print(f\"Test Dataframe: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Training MLPs <a class=\"anchor\" id=\"train-mlps\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Data Preprocessing <a class=\"anchor\" id=\"mlp-data\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_labels = [  # Selecting input features\n",
    "    \"strategy\",\n",
    "    \"board\",\n",
    "    # \"precision\",\n",
    "    \"bit_width\",\n",
    "    # \"integer_bits\",\n",
    "    # \"fractional_bits\",\n",
    "    \"reuse_mean\",\n",
    "    # \"dense_count\",\n",
    "    # \"conv1d_count\",\n",
    "    # \"conv2d_count\",\n",
    "    # \"batchnormalization_count\",\n",
    "    # \"add_count\",\n",
    "    # \"concatenate_count\",\n",
    "    # \"dropout_count\",\n",
    "    # \"relu_count\",\n",
    "    # \"sigmoid_count\",\n",
    "    # \"tanh_count\",\n",
    "    # \"softmax_count\",\n",
    "    # \"dense_parameters_mean\",\n",
    "    # \"dense_inputs_mean\",\n",
    "    # \"dense_outputs_mean\",\n",
    "    # \"dense_reuse_mean\",\n",
    "    \"dense_inputs_mean\",\n",
    "    # \"dense_inputs_min\",\n",
    "    # \"dense_inputs_min_idx\",\n",
    "    # \"dense_inputs_max\",\n",
    "    # \"dense_inputs_max_idx\",\n",
    "    \"dense_outputs_mean\",\n",
    "    # \"dense_outputs_min\",\n",
    "    # \"dense_outputs_min_idx\",\n",
    "    # \"dense_outputs_max\",\n",
    "    # \"dense_outputs_max_idx\",\n",
    "    \"dense_parameters_mean\",\n",
    "    # \"dense_parameters_min\",\n",
    "    # \"dense_parameters_min_idx\",\n",
    "    # \"dense_parameters_max\",\n",
    "    # \"dense_parameters_max_idx\",\n",
    "    \"dense_reuse_mean\",\n",
    "    # \"dense_reuse_min\",\n",
    "    # \"dense_reuse_min_idx\",\n",
    "    # \"dense_reuse_max\",\n",
    "    # \"dense_reuse_max_idx\",\n",
    "    \"dense_count\",\n",
    "    # \"conv1d_parameters_mean\",\n",
    "    # \"conv1d_inputs_mean\",\n",
    "    # \"conv1d_outputs_mean\",\n",
    "    # \"conv1d_reuse_mean\",\n",
    "    \"conv1d_inputs_mean\",\n",
    "    # \"conv1d_inputs_min\",\n",
    "    # \"conv1d_inputs_min_idx\",\n",
    "    # \"conv1d_inputs_max\",\n",
    "    # \"conv1d_inputs_max_idx\",\n",
    "    \"conv1d_outputs_mean\",\n",
    "    # \"conv1d_outputs_min\",\n",
    "    # \"conv1d_outputs_min_idx\",\n",
    "    # \"conv1d_outputs_max\",\n",
    "    # \"conv1d_outputs_max_idx\",\n",
    "    \"conv1d_parameters_mean\",\n",
    "    # \"conv1d_parameters_min\",\n",
    "    # \"conv1d_parameters_min_idx\",\n",
    "    # \"conv1d_parameters_max\",\n",
    "    # \"conv1d_parameters_max_idx\",\n",
    "    \"conv1d_reuse_mean\",\n",
    "    # \"conv1d_reuse_min\",\n",
    "    # \"conv1d_reuse_min_idx\",\n",
    "    # \"conv1d_reuse_max\",\n",
    "    # \"conv1d_reuse_max_idx\",\n",
    "    \"conv1d_count\",\n",
    "    # \"conv2d_parameters_mean\",\n",
    "    # \"conv2d_inputs_mean\",\n",
    "    # \"conv2d_outputs_mean\",\n",
    "    # \"conv2d_reuse_mean\",\n",
    "    \"conv2d_inputs_mean\",\n",
    "    # \"conv2d_inputs_min\",\n",
    "    # \"conv2d_inputs_min_idx\",\n",
    "    # \"conv2d_inputs_max\",\n",
    "    # \"conv2d_inputs_max_idx\",\n",
    "    \"conv2d_outputs_mean\",\n",
    "    # \"conv2d_outputs_min\",\n",
    "    # \"conv2d_outputs_min_idx\",\n",
    "    # \"conv2d_outputs_max\",\n",
    "    # \"conv2d_outputs_max_idx\",\n",
    "    \"conv2d_parameters_mean\",\n",
    "    # \"conv2d_parameters_min\",\n",
    "    # \"conv2d_parameters_min_idx\",\n",
    "    # \"conv2d_parameters_max\",\n",
    "    # \"conv2d_parameters_max_idx\",\n",
    "    \"conv2d_reuse_mean\",\n",
    "    # \"conv2d_reuse_min\",\n",
    "    # \"conv2d_reuse_min_idx\",\n",
    "    # \"conv2d_reuse_max\",\n",
    "    # \"conv2d_reuse_max_idx\",\n",
    "    \"conv2d_count\",\n",
    "    \"batchnormalization_inputs_mean\",\n",
    "    # \"batchnormalization_inputs_min\",\n",
    "    # \"batchnormalization_inputs_min_idx\",\n",
    "    # \"batchnormalization_inputs_max\",\n",
    "    # \"batchnormalization_inputs_max_idx\",\n",
    "    \"batchnormalization_outputs_mean\",\n",
    "    # \"batchnormalization_outputs_min\",\n",
    "    # \"batchnormalization_outputs_min_idx\",\n",
    "    # \"batchnormalization_outputs_max\",\n",
    "    # \"batchnormalization_outputs_max_idx\",\n",
    "    \"batchnormalization_parameters_mean\",\n",
    "    # \"batchnormalization_parameters_min\",\n",
    "    # \"batchnormalization_parameters_min_idx\",\n",
    "    # \"batchnormalization_parameters_max\",\n",
    "    # \"batchnormalization_parameters_max_idx\",\n",
    "    \"batchnormalization_count\",\n",
    "    # \"add_inputs_mean\",\n",
    "    # \"add_inputs_min\",\n",
    "    # \"add_inputs_min_idx\",\n",
    "    # \"add_inputs_max\",\n",
    "    # \"add_inputs_max_idx\",\n",
    "    # \"add_outputs_mean\",\n",
    "    # \"add_outputs_min\",\n",
    "    # \"add_outputs_min_idx\",\n",
    "    # \"add_outputs_max\",\n",
    "    # \"add_outputs_max_idx\",\n",
    "    \"add_count\",\n",
    "    # \"concatenate_inputs_mean\",\n",
    "    # \"concatenate_inputs_min\",\n",
    "    # \"concatenate_inputs_min_idx\",\n",
    "    # \"concatenate_inputs_max\",\n",
    "    # \"concatenate_inputs_max_idx\",\n",
    "    # \"concatenate_outputs_mean\",\n",
    "    # \"concatenate_outputs_min\",\n",
    "    # \"concatenate_outputs_min_idx\",\n",
    "    # \"concatenate_outputs_max\",\n",
    "    # \"concatenate_outputs_max_idx\",\n",
    "    \"concatenate_count\",\n",
    "    # \"dropout_inputs_mean\",\n",
    "    # \"dropout_inputs_min\",\n",
    "    # \"dropout_inputs_min_idx\",\n",
    "    # \"dropout_inputs_max\",\n",
    "    # \"dropout_inputs_max_idx\",\n",
    "    # \"dropout_outputs_mean\",\n",
    "    # \"dropout_outputs_min\",\n",
    "    # \"dropout_outputs_min_idx\",\n",
    "    # \"dropout_outputs_max\",\n",
    "    # \"dropout_outputs_max_idx\",\n",
    "    \"dropout_count\",\n",
    "    # \"relu_inputs_mean\",\n",
    "    # \"relu_inputs_min\",\n",
    "    # \"relu_inputs_min_idx\",\n",
    "    # \"relu_inputs_max\",\n",
    "    # \"relu_inputs_max_idx\",\n",
    "    # \"relu_outputs_mean\",\n",
    "    # \"relu_outputs_min\",\n",
    "    # \"relu_outputs_min_idx\",\n",
    "    # \"relu_outputs_max\",\n",
    "    # \"relu_outputs_max_idx\",\n",
    "    \"relu_count\",\n",
    "    # \"sigmoid_inputs_mean\",\n",
    "    # \"sigmoid_inputs_min\",\n",
    "    # \"sigmoid_inputs_min_idx\",\n",
    "    # \"sigmoid_inputs_max\",\n",
    "    # \"sigmoid_inputs_max_idx\",\n",
    "    # \"sigmoid_outputs_mean\",\n",
    "    # \"sigmoid_outputs_min\",\n",
    "    # \"sigmoid_outputs_min_idx\",\n",
    "    # \"sigmoid_outputs_max\",\n",
    "    # \"sigmoid_outputs_max_idx\",\n",
    "    \"sigmoid_count\",\n",
    "    # \"tanh_inputs_mean\",\n",
    "    # \"tanh_inputs_min\",\n",
    "    # \"tanh_inputs_min_idx\",\n",
    "    # \"tanh_inputs_max\",\n",
    "    # \"tanh_inputs_max_idx\",\n",
    "    # \"tanh_outputs_mean\",\n",
    "    # \"tanh_outputs_min\",\n",
    "    # \"tanh_outputs_min_idx\",\n",
    "    # \"tanh_outputs_max\",\n",
    "    # \"tanh_outputs_max_idx\",\n",
    "    \"tanh_count\",\n",
    "    \"softmax_inputs_mean\",\n",
    "    # \"softmax_inputs_min\",\n",
    "    # \"softmax_inputs_min_idx\",\n",
    "    # \"softmax_inputs_max\",\n",
    "    # \"softmax_inputs_max_idx\",\n",
    "    \"softmax_outputs_mean\",\n",
    "    # \"softmax_outputs_min\",\n",
    "    # \"softmax_outputs_min_idx\",\n",
    "    # \"softmax_outputs_max\",\n",
    "    # \"softmax_outputs_max_idx\",\n",
    "    \"softmax_count\",\n",
    "    # \"total_mult\",\n",
    "    # \"total_add\",\n",
    "    # \"total_logical\",\n",
    "    # \"total_lookup\",\n",
    "]\n",
    "\n",
    "train_inputs_df = train_df[feature_labels].copy()\n",
    "test_inputs_df = test_df[feature_labels].copy()\n",
    "\n",
    "# train_inputs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_labels = [\"bram\"]\n",
    "\n",
    "train_targets_df = train_df[target_labels].copy()\n",
    "test_targets_df = test_df[target_labels].copy()\n",
    "\n",
    "train_targets_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 Building and Training <a class=\"anchor\" id=\"fit-mlps\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rule4ml.models.estimators import MLPSettings, ModelWrapper\n",
    "\n",
    "input_shape = (None, len(train_inputs_df.columns))\n",
    "output_shape = (None, len(train_targets_df.columns))\n",
    "\n",
    "bram_mlp_settings = MLPSettings(\n",
    "    embedding_outputs=[16 for _ in range(len(global_categorical_maps))],\n",
    "    numerical_dense_layers=[32, 16, 32],\n",
    "    dense_layers=[256, 256, 256, 64, 32, 64, 64],\n",
    "    dense_dropouts=[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    ")\n",
    "dsp_mlp_settings = MLPSettings(\n",
    "    embedding_outputs=[16 for _ in range(len(global_categorical_maps))],\n",
    "    numerical_dense_layers=[64, 32, 32],\n",
    "    dense_layers=[256, 16, 32, 32, 64],\n",
    "    dense_dropouts=[0.0, 0.0, 0.0, 0.0, 0.0],\n",
    ")\n",
    "ff_mlp_settings = MLPSettings(\n",
    "    embedding_outputs=[16 for _ in range(len(global_categorical_maps))],\n",
    "    numerical_dense_layers=[64, 16, 32],\n",
    "    dense_layers=[64, 128, 64, 256, 32],\n",
    "    dense_dropouts=[0.0, 0.0, 0.0, 0.0, 0.0],\n",
    ")\n",
    "lut_mlp_settings = MLPSettings(\n",
    "    embedding_outputs=[16 for _ in range(len(global_categorical_maps))],\n",
    "    numerical_dense_layers=[64, 16, 32, 32],\n",
    "    dense_layers=[64, 128, 128, 64],\n",
    "    dense_dropouts=[0.0, 0.0, 0.0, 0.0],\n",
    ")\n",
    "cycles_mlp_settings = MLPSettings(\n",
    "    embedding_outputs=[16 for _ in range(len(global_categorical_maps))],\n",
    "    numerical_dense_layers=[32, 16, 64],\n",
    "    dense_layers=[256, 32, 32, 32, 256, 128, 128, 32, 16, 16, 64],\n",
    "    dense_dropouts=[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    ")\n",
    "\n",
    "vsynth_bram_mlp_settings = MLPSettings(\n",
    "    embedding_outputs=[16, 4],\n",
    "    numerical_dense_layers=[32, 16, 16, 16],\n",
    "    dense_layers=[16, 16, 16, 16, 16, 16, 16, 16],\n",
    "    dense_dropouts=[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    ")\n",
    "vsynth_dsp_mlp_settings = MLPSettings(\n",
    "    embedding_outputs=[16 for _ in range(len(global_categorical_maps))],\n",
    "    numerical_dense_layers=[16, 256, 64, 256, 64],\n",
    "    dense_layers=[16, 256, 128, 16, 16, 64],\n",
    "    dense_dropouts=[0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    ")\n",
    "vsynth_ff_mlp_settings = MLPSettings(\n",
    "    embedding_outputs=[16 for _ in range(len(global_categorical_maps))],\n",
    "    numerical_dense_layers=[64, 256, 128, 16, 256],\n",
    "    dense_layers=[64, 128, 128, 16, 32, 256, 64],\n",
    "    dense_dropouts=[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    ")\n",
    "vsynth_lut_mlp_settings = MLPSettings(\n",
    "    embedding_outputs=[8, 16],\n",
    "    numerical_dense_layers=[256],\n",
    "    dense_layers=[64, 32, 16, 32, 32],\n",
    "    dense_dropouts=[0.0, 0.0, 0.0, 0.0],\n",
    ")\n",
    "vsynth_cycles_mlp_settings = MLPSettings(\n",
    "    embedding_outputs=[16 for _ in range(len(global_categorical_maps))],\n",
    "    numerical_dense_layers=[64, 256, 128, 16, 256],\n",
    "    dense_layers=[64, 128, 128, 16, 32, 256, 64],\n",
    "    dense_dropouts=[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    ")\n",
    "\n",
    "target_labels = [\"bram\"]\n",
    "mlp_settings = vsynth_bram_mlp_settings\n",
    "\n",
    "model_wrapper = ModelWrapper()\n",
    "model_wrapper.build_mlp_model(\n",
    "    mlp_settings,\n",
    "    input_shape=input_shape,\n",
    "    output_shape=output_shape,\n",
    "    categorical_maps=global_categorical_maps,\n",
    "    model_name=f\"{'-'.join([x.upper() for x in target_labels])}_MLP\",\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rule4ml.models.estimators import TrainSettings\n",
    "from rule4ml.models.metrics import parametric_smape, parametric_r2\n",
    "\n",
    "smape = parametric_smape(0, \"-\".join([x.upper() for x in target_labels]))\n",
    "r2 = parametric_r2(0, \"-\".join([x.upper() for x in target_labels]))\n",
    "\n",
    "bram_train_settings = TrainSettings(\n",
    "    num_epochs=50,\n",
    "    batch_size=64,\n",
    "    learning_rate=1e-4,\n",
    "    loss_function=\"mae\",\n",
    "    metrics=[smape, r2],\n",
    ")\n",
    "dsp_train_settings = TrainSettings(\n",
    "    num_epochs=50,\n",
    "    batch_size=32,\n",
    "    learning_rate=1e-4,\n",
    "    loss_function=\"mae\",\n",
    "    metrics=[smape, r2],\n",
    ")\n",
    "ff_train_settings = TrainSettings(\n",
    "    num_epochs=50,\n",
    "    batch_size=64,\n",
    "    learning_rate=1e-4,\n",
    "    loss_function=\"mae\",\n",
    "    metrics=[smape, r2],\n",
    ")\n",
    "lut_train_settings = TrainSettings(\n",
    "    num_epochs=50,\n",
    "    batch_size=32,\n",
    "    learning_rate=1e-4,\n",
    "    loss_function=\"mae\",\n",
    "    metrics=[smape, r2],\n",
    ")\n",
    "cycles_train_settings = TrainSettings(\n",
    "    num_epochs=50,\n",
    "    batch_size=64,\n",
    "    learning_rate=1e-3,\n",
    "    loss_function=\"mae\",\n",
    "    metrics=[smape, r2],\n",
    ")\n",
    "\n",
    "vsynth_bram_train_settings = TrainSettings(\n",
    "    num_epochs=20,\n",
    "    batch_size=128,\n",
    "    learning_rate=1e-3,\n",
    "    loss_function=\"msle\",\n",
    "    metrics=[smape, r2],\n",
    ")\n",
    "vsynth_dsp_train_settings = TrainSettings(\n",
    "    num_epochs=20,\n",
    "    batch_size=256,\n",
    "    learning_rate=1e-4,\n",
    "    loss_function=\"msle\",\n",
    "    metrics=[smape, r2],\n",
    ")\n",
    "vsynth_ff_train_settings = TrainSettings(\n",
    "    num_epochs=20,\n",
    "    batch_size=128,\n",
    "    learning_rate=1e-4,\n",
    "    loss_function=\"msle\",\n",
    "    metrics=[smape, r2],\n",
    ")\n",
    "vsynth_lut_train_settings = TrainSettings(\n",
    "    num_epochs=20,\n",
    "    batch_size=64,\n",
    "    learning_rate=1e-3,\n",
    "    loss_function=\"msle\",\n",
    "    metrics=[smape, r2],\n",
    ")\n",
    "vsynth_cycles_train_settings = TrainSettings(\n",
    "    num_epochs=20,\n",
    "    batch_size=128,\n",
    "    learning_rate=1e-4,\n",
    "    loss_function=\"msle\",\n",
    "    metrics=[smape, r2],\n",
    ")\n",
    "\n",
    "train_settings = vsynth_bram_train_settings\n",
    "\n",
    "model_wrapper.build_dataset(\n",
    "    train_inputs_df,\n",
    "    train_targets_df,\n",
    "    train_settings.batch_size,\n",
    "    val_ratio=0.2,\n",
    "    train_repeats=10,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint, TensorBoard\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "start_time = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "log_dir = os.path.join(\"./logs\", f\"{model_wrapper.model.name}_{start_time}\")\n",
    "checkpoint_dir = os.path.join(\"./checkpoints\", f\"{model_wrapper.model.name}_{start_time}\")\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "checkpoint_file = os.path.join(checkpoint_dir, f\"{'-'.join(target_labels)}_best.weights.h5\")\n",
    "\n",
    "tensorboard_callback = TensorBoard(\n",
    "    log_dir=log_dir,\n",
    "    histogram_freq=1,\n",
    "    write_graph=True,\n",
    "    write_images=True,\n",
    "    write_steps_per_second=False,\n",
    "    update_freq=\"epoch\",\n",
    "    embeddings_freq=1,\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_file,\n",
    "    save_weights_only=True,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if (epoch + 1) % 20 == 0:\n",
    "        return lr * np.exp(-0.2)\n",
    "    return lr\n",
    "\n",
    "\n",
    "lr_callback = LearningRateScheduler(scheduler)\n",
    "\n",
    "callbacks = [\n",
    "    tensorboard_callback,\n",
    "    checkpoint_callback,\n",
    "    # lr_callback\n",
    "]\n",
    "\n",
    "fit_history = model_wrapper.fit(train_settings, callbacks=callbacks, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Training Transformers <a class=\"anchor\" id=\"train-transformers\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1 Data Preprocessing <a class=\"anchor\" id=\"transformer-data\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_feature_labels = [\n",
    "    \"strategy\",\n",
    "    \"board\",\n",
    "    \"bit_width\",\n",
    "    \"reuse_mean\",\n",
    "    \"dense_inputs_mean\",\n",
    "    \"dense_outputs_mean\",\n",
    "    \"dense_parameters_mean\",\n",
    "    \"dense_reuse_mean\",\n",
    "    \"dense_count\",\n",
    "    \"conv1d_inputs_mean\",\n",
    "    \"conv1d_outputs_mean\",\n",
    "    \"conv1d_parameters_mean\",\n",
    "    \"conv1d_reuse_mean\",\n",
    "    \"conv1d_count\",\n",
    "    \"conv2d_inputs_mean\",\n",
    "    \"conv2d_outputs_mean\",\n",
    "    \"conv2d_parameters_mean\",\n",
    "    \"conv2d_reuse_mean\",\n",
    "    \"conv2d_count\",\n",
    "    \"batchnormalization_inputs_mean\",\n",
    "    \"batchnormalization_outputs_mean\",\n",
    "    \"batchnormalization_parameters_mean\",\n",
    "    \"batchnormalization_count\",\n",
    "    \"add_count\",\n",
    "    \"concatenate_count\",\n",
    "    \"dropout_count\",\n",
    "    \"relu_count\",\n",
    "    \"sigmoid_count\",\n",
    "    \"tanh_count\",\n",
    "    \"softmax_inputs_mean\",\n",
    "    \"softmax_outputs_mean\",\n",
    "    \"softmax_count\",\n",
    "]\n",
    "sequential_feature_labels = [\n",
    "    \"layer_type\",\n",
    "    \"layer_input_size\",\n",
    "    \"layer_output_size\",\n",
    "    \"layer_parameter_count\",\n",
    "    \"layer_reuse\",\n",
    "]\n",
    "\n",
    "feature_labels = global_feature_labels\n",
    "if len(sequential_feature_labels) > 0:\n",
    "    feature_labels += [\"sequential_inputs\"]\n",
    "inputs_df = train_df[feature_labels].copy()\n",
    "inputs_df[\"sequential_inputs\"] = inputs_df[\"sequential_inputs\"].apply(\n",
    "    lambda x: x[sequential_feature_labels]\n",
    ")\n",
    "\n",
    "inputs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_df[\"sequential_inputs\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_labels = [\"lut\"]\n",
    "targets_df = train_df[target_labels].copy()\n",
    "targets_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 Building and Training <a class=\"anchor\" id=\"fit-transformers\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rule4ml.models.estimators import TransformerSettings, ModelWrapper\n",
    "\n",
    "global_input_shape = (None, len(inputs_df.columns) - 1)  # not considering \"sequential_inputs\"\n",
    "sequential_input_shape = (None, len(inputs_df[\"sequential_inputs\"].iloc[0].columns))\n",
    "output_shape = (None, len(targets_df.columns))\n",
    "\n",
    "model_wrapper = ModelWrapper()\n",
    "model_wrapper.build_transformer_model(\n",
    "    TransformerSettings(\n",
    "        global_dense_layers=[128, 192, 192],\n",
    "        seq_dense_layers=[32, 64, 96],\n",
    "        global_numerical_dense_layers=[16, 8],\n",
    "        seq_numerical_dense_layers=[32],\n",
    "        num_blocks=1,\n",
    "        num_heads=8,\n",
    "        ff_dim=256,\n",
    "        output_dim=192,\n",
    "        dropout_rate=0.2,\n",
    "        embedding_outputs=[24, 24, 16, 8],\n",
    "        dense_layers=[192, 128, 64, 32, 64, 128, 256, 32],\n",
    "        dense_dropouts=[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "    ),\n",
    "    global_input_shape=global_input_shape,\n",
    "    sequential_input_shape=sequential_input_shape,\n",
    "    output_shape=output_shape,\n",
    "    global_categorical_maps=global_categorical_maps,\n",
    "    sequential_categorical_maps=sequential_categorical_maps,\n",
    "    model_name=f\"{'-'.join([x.upper() for x in target_labels])}_Transformer\",\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rule4ml.models.estimators import TrainSettings\n",
    "\n",
    "train_settings = TrainSettings(num_epochs=20)\n",
    "model_wrapper.build_dataset(\n",
    "    inputs_df,\n",
    "    targets_df,\n",
    "    train_settings.batch_size,\n",
    "    val_ratio=0.15,\n",
    "    train_repeats=1,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint, TensorBoard\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "start_time = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "log_dir = os.path.join(\"./logs\", f\"{model_wrapper.model.name}_{start_time}\")\n",
    "checkpoint_dir = os.path.join(\"./checkpoints\", f\"{model_wrapper.model.name}_{start_time}\")\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "checkpoint_file = os.path.join(checkpoint_dir, f\"{'-'.join(target_labels)}_best.weights.h5\")\n",
    "\n",
    "tensorboard_callback = TensorBoard(\n",
    "    log_dir=log_dir,\n",
    "    histogram_freq=1,\n",
    "    write_graph=True,\n",
    "    write_images=True,\n",
    "    write_steps_per_second=False,\n",
    "    update_freq=\"epoch\",\n",
    "    embeddings_freq=1,\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_file,\n",
    "    save_weights_only=True,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if (epoch + 1) % 20 == 0:\n",
    "        return lr * np.exp(-0.2)\n",
    "    return lr\n",
    "\n",
    "\n",
    "lr_callback = LearningRateScheduler(scheduler)\n",
    "\n",
    "callbacks = [\n",
    "    tensorboard_callback,\n",
    "    checkpoint_callback,\n",
    "    # lr_callback\n",
    "]\n",
    "\n",
    "fit_history = model_wrapper.fit(train_settings, callbacks=callbacks, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Finetuning (Optional) <a class=\"anchor\" id=\"finetune\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.1 Finetuning an MLP <a class=\"anchor\" id=\"finetune-mlp\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rule4ml.models.tuning import Searcher\n",
    "from rule4ml.models.estimators import ModelWrapper\n",
    "\n",
    "target_labels = [\"bram\"]\n",
    "\n",
    "train_targets_df = train_df[target_labels].copy()\n",
    "test_targets_df = test_df[target_labels].copy()\n",
    "\n",
    "model_wrapper = ModelWrapper()\n",
    "searcher = Searcher(model_wrapper)\n",
    "searcher.mlp_search(\n",
    "    train_inputs_df,\n",
    "    train_targets_df,\n",
    "    global_categorical_maps,\n",
    "    directory=\"./mlp_search\",\n",
    "    verbose=1,\n",
    ")\n",
    "searcher.tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_labels = [\"dsp\"]\n",
    "\n",
    "train_targets_df = train_df[target_labels].copy()\n",
    "test_targets_df = test_df[target_labels].copy()\n",
    "\n",
    "model_wrapper = ModelWrapper()\n",
    "searcher = Searcher(model_wrapper)\n",
    "searcher.mlp_search(\n",
    "    train_inputs_df,\n",
    "    train_targets_df,\n",
    "    global_categorical_maps,\n",
    "    directory=\"./mlp_search\",\n",
    "    verbose=1,\n",
    ")\n",
    "searcher.tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_labels = [\"ff\"]\n",
    "\n",
    "train_targets_df = train_df[target_labels].copy()\n",
    "test_targets_df = test_df[target_labels].copy()\n",
    "\n",
    "model_wrapper = ModelWrapper()\n",
    "searcher = Searcher(model_wrapper)\n",
    "searcher.mlp_search(\n",
    "    train_inputs_df,\n",
    "    train_targets_df,\n",
    "    global_categorical_maps,\n",
    "    directory=\"./mlp_search\",\n",
    "    verbose=1,\n",
    ")\n",
    "searcher.tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_labels = [\"lut\"]\n",
    "\n",
    "train_targets_df = train_df[target_labels].copy()\n",
    "test_targets_df = test_df[target_labels].copy()\n",
    "\n",
    "model_wrapper = ModelWrapper()\n",
    "searcher = Searcher(model_wrapper)\n",
    "searcher.mlp_search(\n",
    "    train_inputs_df,\n",
    "    train_targets_df,\n",
    "    global_categorical_maps,\n",
    "    directory=\"./mlp_search\",\n",
    "    verbose=1,\n",
    ")\n",
    "searcher.tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_labels = [\"cycles\"]\n",
    "\n",
    "train_targets_df = train_df[target_labels].copy()\n",
    "test_targets_df = test_df[target_labels].copy()\n",
    "\n",
    "model_wrapper = ModelWrapper()\n",
    "searcher = Searcher(model_wrapper)\n",
    "searcher.mlp_search(\n",
    "    train_inputs_df,\n",
    "    train_targets_df,\n",
    "    global_categorical_maps,\n",
    "    directory=\"./mlp_search\",\n",
    "    verbose=1,\n",
    ")\n",
    "searcher.tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_labels = [\"interval\"]\n",
    "\n",
    "train_targets_df = train_df[target_labels].copy()\n",
    "test_targets_df = test_df[target_labels].copy()\n",
    "\n",
    "model_wrapper = ModelWrapper()\n",
    "searcher = Searcher(model_wrapper)\n",
    "searcher.mlp_search(\n",
    "    train_inputs_df,\n",
    "    train_targets_df,\n",
    "    global_categorical_maps,\n",
    "    directory=\"./mlp_search\",\n",
    "    verbose=1,\n",
    ")\n",
    "searcher.tuner.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.2 Loading and Retraining <a class=\"anchor\" id=\"load-tuner\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rule4ml.models.tuning import Searcher\n",
    "from rule4ml.models.estimators import ModelWrapper\n",
    "\n",
    "model_wrapper = ModelWrapper()\n",
    "searcher = Searcher(model_wrapper)\n",
    "searcher.load_tuner(\n",
    "    train_inputs_df,\n",
    "    train_targets_df,\n",
    "    global_categorical_maps,\n",
    "    \"./mlp_search\",\n",
    "    \"20240715-090815\",\n",
    ")\n",
    "searcher.tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rule4ml.models.estimators import TrainSettings\n",
    "\n",
    "model_wrapper = searcher.model_wrapper\n",
    "model_wrapper.fit(searcher.train_settings, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Testing Prediction Models <a class=\"anchor\" id=\"test-models\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Benchmark Networks <a class=\"anchor\" id=\"benchmark-test\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import (\n",
    "    Dense,\n",
    "    Add,\n",
    "    Input,\n",
    "    BatchNormalization,\n",
    "    Conv2D,\n",
    "    Flatten,\n",
    "    Activation,\n",
    ")\n",
    "\n",
    "\n",
    "def get_test_model(name):\n",
    "    model = None\n",
    "    if name == \"jet\":\n",
    "        input_size = 16\n",
    "        inputs = Input(shape=(input_size,))\n",
    "        x = Dense(32, use_bias=True)(inputs)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = Dense(32, use_bias=True)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = Dense(32, use_bias=True)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = Dense(5, use_bias=True)(x)\n",
    "        outputs = Activation(\"softmax\")(x)\n",
    "\n",
    "        model = keras.Model(inputs=inputs, outputs=outputs, name=name)\n",
    "        model.build([None, input_size])\n",
    "\n",
    "    if name == \"quarks\":\n",
    "        input_size = 10\n",
    "        inputs = Input(shape=(input_size,))\n",
    "        x = Dense(32, use_bias=True)(inputs)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = Dense(1, use_bias=True)(x)\n",
    "        outputs = Activation(\"sigmoid\")(x)\n",
    "\n",
    "        model = keras.Model(inputs=inputs, outputs=outputs, name=name)\n",
    "        model.build([None, input_size])\n",
    "\n",
    "    if name == \"anomaly\":\n",
    "        input_size = 128\n",
    "        inputs = Input(shape=(input_size,))\n",
    "        x = Dense(8, use_bias=True)(inputs)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = Dense(4, use_bias=True)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = Dense(128, use_bias=True)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = Dense(4, use_bias=True)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = Dense(128, use_bias=True)(x)\n",
    "        outputs = Activation(\"softmax\")(x)\n",
    "\n",
    "        model = keras.Model(inputs=inputs, outputs=outputs, name=name)\n",
    "        model.build([None, input_size])\n",
    "\n",
    "    if name == \"bipc\":\n",
    "        input_size = 36\n",
    "        inputs = Input(shape=(input_size,))\n",
    "        x = Dense(36, use_bias=False)(inputs)\n",
    "\n",
    "        y = Activation(\"relu\")(x)\n",
    "        for i in range(5):\n",
    "            y = Dense(36, use_bias=False)(y)\n",
    "            y = Add()([x, y])\n",
    "            y = Activation(\"relu\")(y)\n",
    "        outputs = y\n",
    "\n",
    "        model = keras.Model(inputs=inputs, outputs=outputs, name=name)\n",
    "        model.build([None, input_size])\n",
    "\n",
    "    if name == \"cookie\":\n",
    "        input_size = 512\n",
    "        inputs = Input(shape=(input_size,))\n",
    "        x = Dense(4, use_bias=True)(inputs)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = Dense(32, use_bias=True)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = Dense(32, use_bias=True)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = Dense(5, use_bias=True)(x)\n",
    "        outputs = Activation(\"softmax\")(x)\n",
    "\n",
    "        model = keras.Model(inputs=inputs, outputs=outputs, name=name)\n",
    "        model.build([None, input_size])\n",
    "\n",
    "    if name == \"mnist\":\n",
    "        input_size = 784\n",
    "        inputs = Input(shape=(input_size,))\n",
    "        x = Dense(16, use_bias=True)(inputs)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = Dense(10, use_bias=True)(x)\n",
    "        outputs = Activation(\"softmax\")(x)\n",
    "\n",
    "        model = keras.Model(inputs=inputs, outputs=outputs, name=name)\n",
    "        model.build([None, input_size])\n",
    "\n",
    "    if name == \"automlp\":\n",
    "        input_size = 7\n",
    "        inputs = Input(shape=(input_size,))\n",
    "        x = Dense(12, use_bias=True)(inputs)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = Dense(16, use_bias=True)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = Dense(12, use_bias=True)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = Dense(2, use_bias=True)(x)\n",
    "        outputs = Activation(\"softmax\")(x)\n",
    "\n",
    "        model = keras.Model(inputs=inputs, outputs=outputs, name=name)\n",
    "        model.build([None, input_size])\n",
    "\n",
    "    if name == \"particle\":\n",
    "        input_size = 14\n",
    "        inputs = Input(shape=(input_size,))\n",
    "        x = Dense(32, use_bias=True)(inputs)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = Dense(32, use_bias=True)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = Dense(32, use_bias=True)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = Dense(3, use_bias=True)(x)\n",
    "        outputs = Activation(\"softmax\")(x)\n",
    "\n",
    "        model = keras.Model(inputs=inputs, outputs=outputs, name=name)\n",
    "        model.build([None, input_size])\n",
    "\n",
    "    if name == \"custom1\":\n",
    "        input_size = 16\n",
    "        inputs = Input(shape=(input_size,))\n",
    "        x = Dense(64, use_bias=True)(inputs)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = Dense(32, use_bias=True)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = Dense(32, use_bias=True)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = Dense(32, use_bias=True)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = Dense(10, use_bias=True)(x)\n",
    "        outputs = Activation(\"softmax\")(x)\n",
    "\n",
    "        model = keras.Model(inputs=inputs, outputs=outputs, name=name)\n",
    "        model.build([None, input_size])\n",
    "\n",
    "    if name == \"custom2\":\n",
    "        input_size = 128\n",
    "        inputs = Input(shape=(input_size,))\n",
    "        x = Dense(16, use_bias=True)(inputs)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = Dense(64, use_bias=True)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = Dense(32, use_bias=True)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = Dense(64, use_bias=True)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = Dense(32, use_bias=True)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = Dense(50, use_bias=True)(x)\n",
    "        outputs = Activation(\"softmax\")(x)\n",
    "\n",
    "        model = keras.Model(inputs=inputs, outputs=outputs, name=name)\n",
    "        model.build([None, input_size])\n",
    "\n",
    "    if name == \"custom3\":\n",
    "\n",
    "        def residual_block(x, units):\n",
    "            y = Dense(units)(x)\n",
    "            y = BatchNormalization()(y)\n",
    "            y = Activation(\"relu\")(y)\n",
    "\n",
    "            y = Dense(units)(y)\n",
    "            y = BatchNormalization()(y)\n",
    "\n",
    "            if x.shape[-1] == units:\n",
    "                y = Add()([x, y])\n",
    "            else:\n",
    "                x = Dense(units)(x)\n",
    "                x = BatchNormalization()(x)\n",
    "                y = Add()([x, y])\n",
    "\n",
    "            y = Activation(\"relu\")(y)\n",
    "            return y\n",
    "\n",
    "        input_size = 64\n",
    "        inputs = Input(shape=(input_size,))\n",
    "        x = Dense(32, use_bias=True)(inputs)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "\n",
    "        x = residual_block(x, units=32)\n",
    "        x = residual_block(x, units=32)\n",
    "\n",
    "        x = Dense(10)(x)\n",
    "        outputs = Activation(\"softmax\")(x)\n",
    "\n",
    "        model = keras.Model(inputs=inputs, outputs=outputs, name=name)\n",
    "        model.build([None, input_size])\n",
    "\n",
    "    if name == \"conv2d-nopool\":\n",
    "        input_size = (16, 16, 1)\n",
    "        inputs = Input(input_size)\n",
    "        x = Conv2D(16, (3, 3), padding=\"same\")(inputs)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = Conv2D(4, (3, 3), padding=\"same\")(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(2, use_bias=True)(x)\n",
    "        outputs = Activation(\"softmax\")(x)\n",
    "\n",
    "        model = keras.Model(inputs=inputs, outputs=outputs, name=name)\n",
    "        model.build([None, input_size])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rule4ml.models.estimators import ModelWrapper, MultiModelEstimator\n",
    "import itertools\n",
    "\n",
    "hls_configs = [\n",
    "    {\n",
    "        \"model\": {\n",
    "            \"precision\": \"ap_fixed<8, 3>\",\n",
    "            \"reuse_factor\": 32,\n",
    "            \"strategy\": strategy,\n",
    "            \"bram_factor\": 1000000000,\n",
    "            \"trace_output\": False,\n",
    "        },\n",
    "        \"clock_period\": 10.0,\n",
    "        \"io_type\": \"io_parallel\",\n",
    "        \"board\": board,\n",
    "    }\n",
    "    for board, strategy in itertools.product([\"pynq-z2\", \"zcu102\"], [\"Latency\", \"Resource\"])\n",
    "]\n",
    "\n",
    "model_names = [\n",
    "    \"jet\",\n",
    "    \"quarks\",\n",
    "    \"anomaly\",\n",
    "    \"bipc\",\n",
    "    \"cookie\",\n",
    "    \"mnist\",\n",
    "    \"automlp\",\n",
    "    \"particle\",\n",
    "    \"custom1\",\n",
    "    \"custom2\",\n",
    "    \"custom3\",\n",
    "]\n",
    "models = [get_test_model(name) for name in model_names]\n",
    "\n",
    "target_labels = [\"bram\", \"dsp\", \"ff\", \"lut\", \"cycles\"]\n",
    "\n",
    "estimator = MultiModelEstimator()\n",
    "for label in target_labels:\n",
    "    model_wrapper = ModelWrapper()\n",
    "    model_wrapper.load(\n",
    "        f\"./models/best_{label.upper()}_MLP_config.json\",\n",
    "        f\"./models/best_{label.upper()}_MLP.weights.h5\",\n",
    "    )\n",
    "    estimator.add_model_wrapper(model_wrapper)\n",
    "\n",
    "prediction_df = estimator.predict(models, hls_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df.sort_values([\"Board\", \"Strategy\", \"Reuse Factor\"]).round(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Plots <a class=\"anchor\" id=\"plots\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 Box Plots <a class=\"anchor\" id=\"box-plots\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "from rule4ml.parsers.data_parser import (\n",
    "    read_from_json,\n",
    "    get_global_data,\n",
    "    get_sequential_data,\n",
    "    to_dataframe,\n",
    ")\n",
    "\n",
    "from rule4ml.parsers.data_parser import (\n",
    "    default_board_map,\n",
    "    default_strategy_map,\n",
    "    default_layer_type_map,\n",
    ")\n",
    "\n",
    "data_filter = ParsedDataFilter(\n",
    "    max_output_size=200,\n",
    ")\n",
    "\n",
    "base_path = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "json_data = read_from_json(\n",
    "    os.path.join(base_path, \"datasets/fcnn_dataset_15000.json\"),\n",
    "    data_filter,\n",
    ")\n",
    "\n",
    "meta_data, global_inputs, targets = get_global_data(json_data)\n",
    "sequential_inputs = get_sequential_data(json_data)\n",
    "\n",
    "# Ordinal encoding of categorical inputs\n",
    "global_categorical_maps = {\n",
    "    \"strategy\": default_strategy_map,\n",
    "    \"board\": default_board_map,\n",
    "}\n",
    "sequential_categorical_maps = {\n",
    "    \"layer_type\": default_layer_type_map,\n",
    "}\n",
    "\n",
    "df = to_dataframe(\n",
    "    meta_data=meta_data,\n",
    "    global_inputs=global_inputs,\n",
    "    sequential_inputs=sequential_inputs,\n",
    "    global_categorical_maps=global_categorical_maps,\n",
    "    sequential_categorical_maps=sequential_categorical_maps,\n",
    "    targets=targets,\n",
    ")\n",
    "\n",
    "seed_num = 1337\n",
    "np.random.seed(seed_num)\n",
    "keras.utils.set_random_seed(seed_num)\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.05, random_state=seed_num)\n",
    "\n",
    "feature_labels = [\n",
    "    \"strategy\",\n",
    "    \"board\",\n",
    "    \"bit_width\",\n",
    "    \"reuse_mean\",\n",
    "    \"dense_inputs_mean\",\n",
    "    \"dense_inputs_min\",\n",
    "    \"dense_inputs_min_idx\",\n",
    "    \"dense_inputs_max\",\n",
    "    \"dense_inputs_max_idx\",\n",
    "    \"dense_outputs_mean\",\n",
    "    \"dense_outputs_min\",\n",
    "    \"dense_outputs_min_idx\",\n",
    "    \"dense_outputs_max\",\n",
    "    \"dense_outputs_max_idx\",\n",
    "    \"dense_parameters_mean\",\n",
    "    \"dense_parameters_min\",\n",
    "    \"dense_parameters_min_idx\",\n",
    "    \"dense_parameters_max\",\n",
    "    \"dense_parameters_max_idx\",\n",
    "    \"dense_reuse_mean\",\n",
    "    \"dense_reuse_min\",\n",
    "    \"dense_reuse_min_idx\",\n",
    "    \"dense_reuse_max\",\n",
    "    \"dense_reuse_max_idx\",\n",
    "    \"dense_count\",\n",
    "    \"batchnormalization_inputs_mean\",\n",
    "    \"batchnormalization_outputs_mean\",\n",
    "    \"batchnormalization_parameters_mean\",\n",
    "    \"batchnormalization_count\",\n",
    "    \"add_count\",\n",
    "    \"concatenate_count\",\n",
    "    \"dropout_count\",\n",
    "    \"relu_count\",\n",
    "    \"sigmoid_count\",\n",
    "    \"tanh_count\",\n",
    "    \"softmax_inputs_mean\",\n",
    "    \"softmax_outputs_mean\",\n",
    "    \"softmax_count\",\n",
    "]\n",
    "\n",
    "test_inputs_df = test_df[feature_labels].copy()\n",
    "print(f\"Test Inputs: {test_inputs_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rule4ml.models.estimators import ModelWrapper\n",
    "\n",
    "prediction_labels = [\"bram\", \"dsp\", \"ff\", \"lut\", \"cycles\"]\n",
    "test_targets_df = test_df[prediction_labels].copy()\n",
    "\n",
    "wrappers = []\n",
    "prediction_errors = []\n",
    "for label in prediction_labels:\n",
    "    wrapper = ModelWrapper()\n",
    "    wrapper.load(\n",
    "        f\"./models/iccad_submit/best_{label.upper()}_MLP_config.json\",\n",
    "        f\"./models/iccad_submit/best_{label.upper()}_MLP.weights.h5\",\n",
    "    )\n",
    "    wrappers.append(wrapper)\n",
    "\n",
    "    pred = wrapper.predict_from_df(test_inputs_df).squeeze()\n",
    "    gn = test_targets_df[label].values\n",
    "\n",
    "    prediction_errors.append(np.abs(gn - pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "plt.rcParams.update({\"font.size\": 16})\n",
    "\n",
    "fig, axis = plt.subplots(2, 2, figsize=(12, 8), width_ratios=[3, 1])\n",
    "axis = np.reshape(axis, -1)\n",
    "fig.subplots_adjust(hspace=0.1, wspace=0.4)\n",
    "\n",
    "flier_ax, box_ax = axis[0], axis[2]\n",
    "\n",
    "iqr_weight = 1.5\n",
    "\n",
    "resources_errors = prediction_errors[:1]\n",
    "resources_labels = prediction_labels[:1]\n",
    "\n",
    "threshold = 10.0\n",
    "below_threshold = []\n",
    "for errors in np.asarray(resources_errors):\n",
    "    below_threshold.append(np.sum(errors < threshold) / len(errors))\n",
    "print(f\"Resources below {threshold}%: {below_threshold}\")\n",
    "print(f\"Resources Mean: {np.mean(below_threshold)}\")\n",
    "\n",
    "bplot = box_ax.boxplot(\n",
    "    resources_errors,\n",
    "    whis=iqr_weight,\n",
    "    tick_labels=[x.upper() for x in resources_labels],\n",
    "    showfliers=True,\n",
    "    showmeans=True,\n",
    "    meanline=True,\n",
    "    vert=True,\n",
    "    patch_artist=True,\n",
    ")\n",
    "fliers = flier_ax.boxplot(\n",
    "    resources_errors,\n",
    "    whis=iqr_weight,\n",
    "    tick_labels=[\"\" for x in resources_labels],\n",
    "    showfliers=True,\n",
    "    showmeans=True,\n",
    "    meanline=True,\n",
    "    vert=True,\n",
    "    patch_artist=True,\n",
    ")\n",
    "\n",
    "colors = [\"pink\", \"yellow\", \"lightgreen\", \"lightblue\", \"FFA500\"]\n",
    "for patch, color in zip(bplot[\"boxes\"], colors):\n",
    "    patch.set_facecolor(color)\n",
    "\n",
    "box_ax.set_ylim(-1, 30)\n",
    "flier_ax.set_ylim(30, 200)\n",
    "\n",
    "box_ax.yaxis.grid(True)\n",
    "box_ax.spines.top.set_visible(False)\n",
    "box_ax.xaxis.tick_bottom()\n",
    "box_ax.set_yticks([0, 5, 10, 15, 20, 25, 30])\n",
    "\n",
    "flier_ax.yaxis.grid(True)\n",
    "flier_ax.spines.bottom.set_visible(False)\n",
    "flier_ax.xaxis.tick_top()\n",
    "flier_ax.set_yticks([30, 50, 75, 100, 125, 150, 175, 200])\n",
    "\n",
    "d = 0.5\n",
    "kwargs = dict(\n",
    "    marker=[(-1, -d), (1, d)],\n",
    "    markersize=12,\n",
    "    linestyle=\"none\",\n",
    "    color=\"k\",\n",
    "    mec=\"k\",\n",
    "    mew=1,\n",
    "    clip_on=False,\n",
    ")\n",
    "flier_ax.plot([0, 1], [0, 0], transform=flier_ax.transAxes, **kwargs)\n",
    "box_ax.plot([0, 1], [1, 1], transform=box_ax.transAxes, **kwargs)\n",
    "\n",
    "median_line = Line2D([0], [0], color=\"orange\", linestyle=\"--\", linewidth=1.5, label=\"Median\")\n",
    "mean_line = Line2D([0], [0], color=\"green\", linestyle=\"--\", linewidth=1.5, label=\"Mean\")\n",
    "\n",
    "handles = [median_line, mean_line]\n",
    "labels = [\"Median\", \"Mean\"]\n",
    "\n",
    "legends = fig.legend(\n",
    "    handles,\n",
    "    labels,\n",
    "    bbox_to_anchor=[0.9, 1],\n",
    "    # loc=\"upper left\",\n",
    "    loc=\"upper right\",\n",
    "    ncol=len(labels) // 2,\n",
    ")\n",
    "\n",
    "ytext = fig.text(0.06, 0.5, \"Error (%)\", va=\"center\", rotation=\"vertical\", size=18)\n",
    "suptitle = fig.suptitle(\"Prediction Errors - Boxplots\", fontsize=20, y=0.95)\n",
    "\n",
    "latency_flier_ax, latency_box_ax = axis[1], axis[3]\n",
    "\n",
    "iqr_weight = 1.5\n",
    "\n",
    "latency_errors = [prediction_errors[4]]\n",
    "latency_labels = [prediction_labels[4]]\n",
    "\n",
    "threshold = 100.0\n",
    "below_threshold = []\n",
    "for errors in np.asarray(latency_errors):\n",
    "    below_threshold.append(np.sum(errors < threshold) / len(errors))\n",
    "print(f\"Latency below {threshold} cycles: {below_threshold}\")\n",
    "\n",
    "latency_bplot = latency_box_ax.boxplot(\n",
    "    latency_errors,\n",
    "    whis=iqr_weight,\n",
    "    widths=0.33,\n",
    "    tick_labels=[\"Cycles\"],\n",
    "    showfliers=True,\n",
    "    showmeans=True,\n",
    "    meanline=True,\n",
    "    vert=True,\n",
    "    patch_artist=True,\n",
    ")\n",
    "latency_fliers = latency_flier_ax.boxplot(\n",
    "    latency_errors,\n",
    "    whis=iqr_weight,\n",
    "    widths=0.33,\n",
    "    tick_labels=[\"\" for x in latency_labels],\n",
    "    showfliers=True,\n",
    "    showmeans=True,\n",
    "    meanline=True,\n",
    "    vert=True,\n",
    "    patch_artist=True,\n",
    ")\n",
    "\n",
    "colors = [\"lightblue\"]\n",
    "for patch, color in zip(latency_bplot[\"boxes\"], colors):\n",
    "    patch.set_facecolor(color)\n",
    "\n",
    "latency_box_ax.set_ylim(-10, 200)\n",
    "latency_flier_ax.set_ylim(200, 650)\n",
    "\n",
    "latency_box_ax.yaxis.grid(True)\n",
    "latency_box_ax.spines.top.set_visible(False)\n",
    "latency_box_ax.xaxis.tick_bottom()\n",
    "latency_box_ax.set_yticks(np.arange(0, 225, 25))\n",
    "\n",
    "latency_flier_ax.yaxis.grid(True)\n",
    "latency_flier_ax.spines.bottom.set_visible(False)\n",
    "latency_flier_ax.xaxis.tick_top()\n",
    "latency_flier_ax.set_yticks(np.arange(200, 700, 100))\n",
    "\n",
    "d = 0.5\n",
    "kwargs = dict(\n",
    "    marker=[(-1, -d), (1, d)],\n",
    "    markersize=12,\n",
    "    linestyle=\"none\",\n",
    "    color=\"k\",\n",
    "    mec=\"k\",\n",
    "    mew=1,\n",
    "    clip_on=False,\n",
    ")\n",
    "latency_flier_ax.plot([0, 1], [0, 0], transform=latency_flier_ax.transAxes, **kwargs)\n",
    "latency_box_ax.plot([0, 1], [1, 1], transform=latency_box_ax.transAxes, **kwargs)\n",
    "\n",
    "latency_ytext = fig.text(0.66, 0.5, \"Error (Cycles)\", va=\"center\", rotation=\"vertical\", size=18)\n",
    "\n",
    "resource_caption = fig.text(0.355, 0.04, \"(a)\", va=\"center\", size=18)\n",
    "latency_caption = fig.text(0.808, 0.04, \"(b)\", va=\"center\", size=18)\n",
    "\n",
    "# fig.savefig(\n",
    "#     \"/mnt/c/Users/Y540/Desktop/box_plot_merged.jpg\",\n",
    "#     dpi=300,\n",
    "#     bbox_extra_artists=(legends, ytext, suptitle, latency_ytext, resource_caption, latency_caption),\n",
    "#     bbox_inches=\"tight\",\n",
    "# )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2 Bar Plots <a class=\"anchor\" id=\"bar-plots\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rule4ml.models.estimators import ModelWrapper, MultiModelEstimator\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "prediction_labels = [\"bram\", \"dsp\", \"ff\", \"lut\", \"cycles\"]\n",
    "\n",
    "model_names = [\n",
    "    \"jet\",\n",
    "    \"quarks\",\n",
    "    \"anomaly\",\n",
    "    \"bipc\",\n",
    "    \"cookie\",\n",
    "    \"mnist\",\n",
    "    \"automlp\",\n",
    "    \"particle\",\n",
    "    \"custom1\",\n",
    "    \"custom2\",\n",
    "    \"custom3\",\n",
    "]\n",
    "test_models = [get_test_model(name) for name in model_names]\n",
    "\n",
    "hls_configs = [\n",
    "    {\n",
    "        \"model\": {\n",
    "            \"precision\": precision,\n",
    "            \"reuse_factor\": reuse,\n",
    "            \"strategy\": strategy,\n",
    "            \"bram_factor\": 1000000000,\n",
    "            \"trace_output\": False,\n",
    "        },\n",
    "        \"clock_period\": 10.0,\n",
    "        \"io_type\": \"io_parallel\",\n",
    "        \"board\": board,\n",
    "    }\n",
    "    for board, strategy, precision, reuse in itertools.product(\n",
    "        [\"pynq-z2\", \"zcu102\"],\n",
    "        [\"Latency\", \"Resource\"],\n",
    "        [\"ap_fixed<2, 1>\", \"ap_fixed<8, 3>\", \"ap_fixed<16, 6>\"],\n",
    "        [1, 2, 4, 8, 16, 32, 64],\n",
    "    )\n",
    "]\n",
    "\n",
    "estimator = MultiModelEstimator()\n",
    "estimator.load_default_models()\n",
    "predictions = []\n",
    "\n",
    "prediction_df = estimator.predict(test_models, hls_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df[\"BRAM\"] = prediction_df[\"BRAM\"].apply(lambda x: min(x, 200.0))\n",
    "prediction_df[\"DSP\"] = prediction_df[\"DSP\"].apply(lambda x: min(x, 200.0))\n",
    "prediction_df[\"FF\"] = prediction_df[\"FF\"].apply(lambda x: min(x, 200.0))\n",
    "prediction_df[\"LUT\"] = prediction_df[\"LUT\"].apply(lambda x: min(x, 200.0))\n",
    "\n",
    "precision_order = [\"ap_fixed<2, 1>\", \"ap_fixed<8, 3>\", \"ap_fixed<16, 6>\"]\n",
    "prediction_df[\"Precision\"] = pd.Categorical(\n",
    "    prediction_df[\"Precision\"], categories=precision_order, ordered=True\n",
    ")\n",
    "\n",
    "prediction_df.head(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rule4ml.parsers.data_parser import (\n",
    "    read_from_json,\n",
    "    get_global_data,\n",
    "    get_sequential_data,\n",
    "    to_dataframe,\n",
    "    default_strategy_map,\n",
    "    default_board_map,\n",
    "    default_layer_type_map,\n",
    ")\n",
    "\n",
    "benchmark_data = read_from_json(\"../datasets/benchmark_data.json\")\n",
    "\n",
    "benchmark_meta_data, benchmark_global_inputs, benchmark_targets = get_global_data(benchmark_data)\n",
    "benchmark_sequential_inputs = get_sequential_data(benchmark_data)\n",
    "\n",
    "global_categorical_maps = {\n",
    "    \"strategy\": default_strategy_map,\n",
    "    \"board\": default_board_map,\n",
    "}\n",
    "sequential_categorical_maps = {\n",
    "    \"layer_type\": default_layer_type_map,\n",
    "}\n",
    "\n",
    "benchmark_df = to_dataframe(\n",
    "    meta_data=benchmark_meta_data,\n",
    "    global_inputs=benchmark_global_inputs,\n",
    "    sequential_inputs=benchmark_sequential_inputs,\n",
    "    global_categorical_maps={},\n",
    "    sequential_categorical_maps={},\n",
    "    targets=benchmark_targets,\n",
    ")\n",
    "benchmark_gn_df = benchmark_df[\n",
    "    [\n",
    "        \"model_name\",\n",
    "        \"board\",\n",
    "        \"strategy\",\n",
    "        \"precision\",\n",
    "        \"global_reuse\",\n",
    "        \"bram\",\n",
    "        \"dsp\",\n",
    "        \"ff\",\n",
    "        \"lut\",\n",
    "        \"cycles\",\n",
    "    ]\n",
    "].copy()\n",
    "benchmark_gn_df = benchmark_gn_df.rename(\n",
    "    {\n",
    "        \"model_name\": \"Model\",\n",
    "        \"board\": \"Board\",\n",
    "        \"strategy\": \"Strategy\",\n",
    "        \"precision\": \"Precision\",\n",
    "        \"global_reuse\": \"Reuse Factor\",\n",
    "        \"bram\": \"BRAM\",\n",
    "        \"dsp\": \"DSP\",\n",
    "        \"ff\": \"FF\",\n",
    "        \"lut\": \"LUT\",\n",
    "        \"cycles\": \"CYCLES\",\n",
    "    },\n",
    "    axis=1,\n",
    ")\n",
    "benchmark_gn_df.loc[benchmark_gn_df[\"Strategy\"] == \"latency\", \"Strategy\"] = \"Latency\"\n",
    "benchmark_gn_df.loc[benchmark_gn_df[\"Strategy\"] == \"resource\", \"Strategy\"] = \"Resource\"\n",
    "\n",
    "benchmark_gn_df[\"BRAM\"] = benchmark_gn_df[\"BRAM\"].apply(lambda x: min(x, 200.0))\n",
    "benchmark_gn_df[\"DSP\"] = benchmark_gn_df[\"DSP\"].apply(lambda x: min(x, 200.0))\n",
    "benchmark_gn_df[\"FF\"] = benchmark_gn_df[\"FF\"].apply(lambda x: min(x, 200.0))\n",
    "benchmark_gn_df[\"LUT\"] = benchmark_gn_df[\"LUT\"].apply(lambda x: min(x, 200.0))\n",
    "\n",
    "precision_order = [\"ap_fixed<2, 1>\", \"ap_fixed<8, 3>\", \"ap_fixed<16, 6>\"]\n",
    "benchmark_gn_df[\"Precision\"] = pd.Categorical(\n",
    "    benchmark_gn_df[\"Precision\"], categories=precision_order, ordered=True\n",
    ")\n",
    "\n",
    "benchmark_gn_df.head(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gn_grouped_mean = (\n",
    "    benchmark_gn_df.groupby([\"Strategy\", \"Board\", \"Precision\", \"Reuse Factor\"])[\n",
    "        [\n",
    "            \"BRAM\",\n",
    "            \"DSP\",\n",
    "            \"FF\",\n",
    "            \"LUT\",\n",
    "            # \"CYCLES\"\n",
    "        ]\n",
    "    ]\n",
    "    .mean()\n",
    "    .round(0)\n",
    "    .astype(int)\n",
    ")\n",
    "\n",
    "prediction_grouped_mean = (\n",
    "    prediction_df.groupby([\"Strategy\", \"Board\", \"Precision\", \"Reuse Factor\"])[\n",
    "        [\n",
    "            \"BRAM\",\n",
    "            \"DSP\",\n",
    "            \"FF\",\n",
    "            \"LUT\",\n",
    "            # \"CYCLES\"\n",
    "        ]\n",
    "    ]\n",
    "    .mean()\n",
    "    .round(0)\n",
    "    .astype(int)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(\n",
    "    gn_grouped_mean,\n",
    "    prediction_grouped_mean,\n",
    "    on=(\"Strategy\", \"Board\", \"Precision\", \"Reuse Factor\"),\n",
    "    suffixes=(\" (G)\", \" (P)\"),\n",
    ")\n",
    "\n",
    "merged_df = merged_df[\n",
    "    [\n",
    "        \"BRAM (G)\",\n",
    "        \"BRAM (P)\",\n",
    "        \"DSP (G)\",\n",
    "        \"DSP (P)\",\n",
    "        \"FF (G)\",\n",
    "        \"FF (P)\",\n",
    "        \"LUT (G)\",\n",
    "        \"LUT (P)\",\n",
    "        # \"CYCLES (G)\", \"CYCLES (P)\",\n",
    "    ]\n",
    "]\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from rule4ml.parsers.utils import fixed_precision_to_bit_width\n",
    "\n",
    "plt.rcParams.update({\"font.size\": 14})\n",
    "\n",
    "grouped = merged_df.xs((\"pynq-z2\",), level=[\"Board\"]).groupby([\"Precision\", \"Strategy\"])\n",
    "\n",
    "n_groups = len(grouped)\n",
    "n_cols = 2\n",
    "n_rows = 3\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    n_rows, n_cols, dpi=300, figsize=(16, 10), squeeze=False, sharex=True, sharey=False\n",
    ")\n",
    "axes = axes.flatten()\n",
    "\n",
    "width = 0.11\n",
    "colors = [\"#008000\", \"#FF5964\", \"#17BEBB\", \"#FFA500\"]\n",
    "reuse_factors = prediction_df[\"Reuse Factor\"].unique()\n",
    "num_resources = 4\n",
    "resource_gap = 0\n",
    "\n",
    "total_width = num_resources * (2 * width + resource_gap) - resource_gap\n",
    "start = np.arange(1, len(reuse_factors) + 1) - total_width / 2\n",
    "\n",
    "row_idx = 0\n",
    "col_idx = 0\n",
    "for ax, ((precision, strategy), df) in zip(axes, grouped):\n",
    "    for i, (col_gn, col_pred) in enumerate(zip(df.columns[::2], df.columns[1::2])):\n",
    "        gn_vals = df[col_gn]\n",
    "        pred_vals = df[col_pred]\n",
    "\n",
    "        resource_indices = start + i * (2 * width + resource_gap)\n",
    "\n",
    "        for j, reuse_factor in enumerate(reuse_factors):\n",
    "            gn_label = \"\"\n",
    "            pred_label = \"\"\n",
    "            if j == 0:\n",
    "                gn_label = f\"{col_gn}\"\n",
    "                pred_label = f\"{col_pred}\"\n",
    "\n",
    "            ax.bar(\n",
    "                resource_indices[j] - width / 2,\n",
    "                gn_vals[j],\n",
    "                width,\n",
    "                label=gn_label,\n",
    "                color=colors[i % len(colors)],\n",
    "                edgecolor=\"black\",\n",
    "            )\n",
    "            ax.bar(\n",
    "                resource_indices[j] + width / 2,\n",
    "                pred_vals[j],\n",
    "                width,\n",
    "                label=pred_label,\n",
    "                color=colors[i % len(colors)],\n",
    "                edgecolor=\"black\",\n",
    "                hatch=\"///\",\n",
    "            )\n",
    "\n",
    "    total_bits, fraction_bits = fixed_precision_to_bit_width(precision)\n",
    "\n",
    "    ax.set_title(f\"{strategy}, {total_bits}-bit width\")\n",
    "    ax.set_xticks(start + (num_resources - 1) * (width + resource_gap / 2))\n",
    "    ax.set_xticklabels(reuse_factors, rotation=45)\n",
    "\n",
    "    # if col_idx == 0:\n",
    "    #     ax.set_ylabel(\"Utilization (%)\")\n",
    "\n",
    "    # if row_idx == n_rows - 1:\n",
    "    #     ax.set_xlabel(\"Reuse Factor\")\n",
    "\n",
    "    col_idx += 1\n",
    "    if col_idx == n_cols:\n",
    "        row_idx += 1\n",
    "        col_idx = 0\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "legends = fig.legend(\n",
    "    handles,\n",
    "    labels,\n",
    "    title=\"Resources\",\n",
    "    bbox_to_anchor=[0.3, 1.03],\n",
    "    loc=\"upper left\",\n",
    "    # loc=\"upper right\",\n",
    "    ncol=len(labels) // 2,\n",
    ")\n",
    "\n",
    "xtext = fig.text(0.5, 0.035, \"Reuse Factor\", ha=\"center\", size=18)\n",
    "ytext = fig.text(0.07, 0.5, \"Utilization (%)\", va=\"center\", rotation=\"vertical\", size=18)\n",
    "\n",
    "suptitle = fig.suptitle(\"Pynq-Z2: Resource Utilization Trends\", fontsize=20, y=1.075)\n",
    "\n",
    "plt.subplots_adjust(hspace=0.275, wspace=0.125)\n",
    "plt.show()\n",
    "\n",
    "# fig.savefig(\n",
    "#     \"/mnt/c/Users/Y540/Desktop/pynq_avg_bars.jpg\",\n",
    "#     dpi=300,\n",
    "#     bbox_extra_artists=(legends, xtext, ytext, suptitle),\n",
    "#     bbox_inches=\"tight\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\"font.size\": 14})\n",
    "\n",
    "grouped = merged_df.xs((\"zcu102\",), level=[\"Board\"]).groupby([\"Precision\", \"Strategy\"])\n",
    "\n",
    "n_groups = len(grouped)\n",
    "n_cols = 2\n",
    "n_rows = 3\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    n_rows, n_cols, dpi=300, figsize=(16, 10), squeeze=False, sharex=True, sharey=False\n",
    ")\n",
    "axes = axes.flatten()\n",
    "\n",
    "width = 0.11\n",
    "colors = [\"#008000\", \"#FF5964\", \"#17BEBB\", \"#FFA500\"]\n",
    "reuse_factors = prediction_df[\"Reuse Factor\"].unique()\n",
    "num_resources = 4\n",
    "resource_gap = 0\n",
    "\n",
    "total_width = num_resources * (2 * width + resource_gap) - resource_gap\n",
    "start = np.arange(1, len(reuse_factors) + 1) - total_width / 2\n",
    "\n",
    "row_idx = 0\n",
    "col_idx = 0\n",
    "for ax, ((precision, strategy), df) in zip(axes, grouped):\n",
    "    for i, (col_gn, col_pred) in enumerate(zip(df.columns[::2], df.columns[1::2])):\n",
    "        gn_vals = df[col_gn]\n",
    "        pred_vals = df[col_pred]\n",
    "\n",
    "        resource_indices = start + i * (2 * width + resource_gap)\n",
    "\n",
    "        for j, reuse_factor in enumerate(reuse_factors):\n",
    "            gn_label = \"\"\n",
    "            pred_label = \"\"\n",
    "            if j == 0:\n",
    "                gn_label = f\"{col_gn}\"\n",
    "                pred_label = f\"{col_pred}\"\n",
    "\n",
    "            ax.bar(\n",
    "                resource_indices[j] - width / 2,\n",
    "                gn_vals[j],\n",
    "                width,\n",
    "                label=gn_label,\n",
    "                color=colors[i % len(colors)],\n",
    "                edgecolor=\"black\",\n",
    "            )\n",
    "            ax.bar(\n",
    "                resource_indices[j] + width / 2,\n",
    "                pred_vals[j],\n",
    "                width,\n",
    "                label=pred_label,\n",
    "                color=colors[i % len(colors)],\n",
    "                edgecolor=\"black\",\n",
    "                hatch=\"///\",\n",
    "            )\n",
    "\n",
    "    total_bits, fraction_bits = fixed_precision_to_bit_width(precision)\n",
    "\n",
    "    ax.set_title(f\"{strategy}, {total_bits}-bit width\")\n",
    "    ax.set_xticks(start + (num_resources - 1) * (width + resource_gap / 2))\n",
    "    ax.set_xticklabels(reuse_factors, rotation=45)\n",
    "\n",
    "    col_idx += 1\n",
    "    if col_idx == n_cols:\n",
    "        row_idx += 1\n",
    "        col_idx = 0\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "legends = fig.legend(\n",
    "    handles,\n",
    "    labels,\n",
    "    title=\"Resources\",\n",
    "    bbox_to_anchor=[0.3, 1.03],\n",
    "    loc=\"upper left\",\n",
    "    ncol=len(labels) // 2,\n",
    ")\n",
    "\n",
    "xtext = fig.text(0.5, 0.035, \"Reuse Factor\", ha=\"center\", size=18)\n",
    "ytext = fig.text(0.07, 0.5, \"Utilization (%)\", va=\"center\", rotation=\"vertical\", size=18)\n",
    "\n",
    "suptitle = fig.suptitle(\"ZCU102: Resource Utilization Trends\", fontsize=20, y=1.075)\n",
    "\n",
    "plt.subplots_adjust(hspace=0.275, wspace=0.125)\n",
    "plt.show()\n",
    "\n",
    "# fig.savefig(\n",
    "#     \"/mnt/c/Users/Y540/Desktop/zcu_avg_bars.jpg\",\n",
    "#     dpi=300,\n",
    "#     bbox_extra_artists=(legends, xtext, ytext, suptitle),\n",
    "#     bbox_inches=\"tight\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gn_grouped_mean = (\n",
    "    benchmark_gn_df.groupby([\"Strategy\", \"Board\", \"Precision\", \"Reuse Factor\"])[[\"CYCLES\"]]\n",
    "    .mean()\n",
    "    .round(0)\n",
    "    .astype(int)\n",
    ")\n",
    "\n",
    "prediction_grouped_mean = (\n",
    "    prediction_df.groupby([\"Strategy\", \"Board\", \"Precision\", \"Reuse Factor\"])[[\"CYCLES\"]]\n",
    "    .mean()\n",
    "    .round(0)\n",
    "    .astype(int)\n",
    ")\n",
    "\n",
    "merged_df = pd.merge(\n",
    "    gn_grouped_mean,\n",
    "    prediction_grouped_mean,\n",
    "    on=(\"Strategy\", \"Board\", \"Precision\", \"Reuse Factor\"),\n",
    "    suffixes=(\" (G)\", \" (P)\"),\n",
    ")\n",
    "\n",
    "merged_df = merged_df[\n",
    "    [\n",
    "        \"CYCLES (G)\",\n",
    "        \"CYCLES (P)\",\n",
    "    ]\n",
    "]\n",
    "merged_df.head()\n",
    "\n",
    "plt.rcParams.update({\"font.size\": 14})\n",
    "\n",
    "grouped = merged_df.groupby([\"Board\", \"Strategy\", \"Precision\"])\n",
    "\n",
    "n_groups = len(grouped)\n",
    "n_cols = 3\n",
    "n_rows = (n_groups // n_cols) + (n_groups % n_cols > 0)\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    n_rows, n_cols, dpi=300, figsize=(16, 10), squeeze=False, sharex=True, sharey=False\n",
    ")\n",
    "axes = axes.flatten()\n",
    "\n",
    "width = 0.35\n",
    "colors = [\"#17BEBB\", \"#FFA500\"]\n",
    "reuse_factors = prediction_df[\"Reuse Factor\"].unique()\n",
    "num_resources = 1\n",
    "resource_gap = 0\n",
    "\n",
    "total_width = num_resources * (2 * width + resource_gap) - resource_gap\n",
    "start = np.arange(1, len(reuse_factors) + 1) - total_width / 2\n",
    "\n",
    "row_idx = 0\n",
    "col_idx = 0\n",
    "for ax, ((board, strategy, precision), df) in zip(axes, grouped):\n",
    "    for i, (col_gn, col_pred) in enumerate(zip(df.columns[::2], df.columns[1::2])):\n",
    "        gn_vals = df[col_gn]\n",
    "        pred_vals = df[col_pred]\n",
    "\n",
    "        resource_indices = start + i * (2 * width + resource_gap)\n",
    "\n",
    "        for j, reuse_factor in enumerate(reuse_factors):\n",
    "            gn_label = \"\"\n",
    "            pred_label = \"\"\n",
    "            if j == 0:\n",
    "                gn_label = f\"{col_gn}\"\n",
    "                pred_label = f\"{col_pred}\"\n",
    "\n",
    "            ax.bar(\n",
    "                resource_indices[j] - width / 2,\n",
    "                gn_vals[j],\n",
    "                width,\n",
    "                label=gn_label,\n",
    "                color=colors[i % len(colors)],\n",
    "                edgecolor=\"black\",\n",
    "            )\n",
    "            ax.bar(\n",
    "                resource_indices[j] + width / 2,\n",
    "                pred_vals[j],\n",
    "                width,\n",
    "                label=pred_label,\n",
    "                color=colors[i % len(colors) + 1],\n",
    "                edgecolor=\"black\",\n",
    "                hatch=\"///\",\n",
    "            )\n",
    "\n",
    "    total_bits, fraction_bits = fixed_precision_to_bit_width(precision)\n",
    "\n",
    "    ax.set_title(f\"{board}, {strategy}, {total_bits}-bit width\")\n",
    "    ax.set_xticks(start + (num_resources - 1) * (width + resource_gap / 2))\n",
    "    ax.set_xticklabels(reuse_factors, rotation=45)\n",
    "\n",
    "    col_idx += 1\n",
    "    if col_idx == n_cols:\n",
    "        row_idx += 1\n",
    "        col_idx = 0\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "legends = fig.legend(handles, labels, bbox_to_anchor=[0.8, 1], loc=\"upper left\")\n",
    "\n",
    "xtext = fig.text(0.5, 0.05, \"Reuse Factor\", ha=\"center\", size=18)\n",
    "ytext = fig.text(0.07, 0.5, \"Cycles\", va=\"center\", rotation=\"vertical\", size=18)\n",
    "\n",
    "fig.suptitle(\"Clock Cycle Trends\", fontsize=20)\n",
    "\n",
    "plt.subplots_adjust(hspace=0.4, wspace=0.2)\n",
    "plt.show()\n",
    "\n",
    "# fig.savefig(\n",
    "#     \"/mnt/c/Users/Y540/Desktop/cycles_avg_bars.jpg\",\n",
    "#     dpi=300,\n",
    "#     bbox_extra_artists=(legends, xtext, ytext),\n",
    "#     bbox_inches=\"tight\",\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
